{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# explore_bis_v3\n",
        "\n",
        "Notebook simplifié montrant comment utiliser les blocs **ENC** et **MEM**\n",
        "exposés par la librairie `hdc_project.encoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4471c8d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using src path: /Users/aymenmejri/Desktop/MyCode/experiments/hdc_v2/hdc_project/src\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "ROOT = Path.cwd().parent\n",
        "SRC = ROOT / \"src\"\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n",
        "print(f'Using src path: {SRC}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5984d662",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from hdc_project.encoder import m4, pipeline as enc_pipeline\n",
        "from hdc_project.encoder.mem import pipeline as mem_pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e1f6e16",
      "metadata": {},
      "source": [
        "\n",
        "## Chargement du sous-corpus OPUS\n",
        "\n",
        "On réutilise `opus_load_subset` depuis la librairie pour récupérer un petit\n",
        "sous-échantillon bilingue (EN/FR). En environnement hors-ligne, un jeu de\n",
        "repli est utilisé pour que le notebook reste exécutable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a58ced34",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPUS subset loaded: 10000 pairs\n",
            "ENC sample size: 10000\n",
            "MEM sample size: 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 10000/10000 [00:26<00:00, 381.24it/s]\n",
            "Processing: 100%|██████████| 10000/10000 [00:26<00:00, 381.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded 10000 sentences; signature shape = (8192,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [07:08<00:00, 23.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "intra=0.0009, inter(abs)=0.0253, inter segments=0.0089\n",
            "majority curve (eta=0): [(1, 0.0), (2, 0.0)]\n",
            "Pairs available for MEM training: 37968\n",
            "Training complete; few bucket counts: [249 229 310 312 265 289 325 291 326 361 249 251 224 314 335 299 287 308\n",
            " 255 302 318 347 296 319 249 297 259 312 271 270 345 281 287 257 305 318\n",
            " 301 303 321 308 326 307 280 261 338 296 279 330 259 224 269 284 252 293\n",
            " 394 297 332 343 256 333 336 246 293 266]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 2307.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 mean similarity over 200 span-probes: 0.2727\n",
            "Top-1 median similarity: 0.2773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from hdc_project.encoder import m4, pipeline as enc_pipeline\n",
        "from hdc_project.encoder.mem import pipeline as mem_pipeline\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Chargement données OPUS\n",
        "# ----------------------------\n",
        "try:\n",
        "    ens_raw, frs_raw = enc_pipeline.opus_load_subset(\n",
        "        name=\"opus_books\",\n",
        "        config=\"en-fr\",\n",
        "        split=\"train\",\n",
        "        N=10_000,\n",
        "        seed=2025,\n",
        "    )\n",
        "    print(f\"OPUS subset loaded: {len(ens_raw)} pairs\")\n",
        "except Exception as exc:\n",
        "    print(\"Warning: OPUS download failed, falling back to local toy corpus.\")\n",
        "    print(f\"Original error: {exc}\")\n",
        "    ens_raw = [\n",
        "        \"hyperdimensional computing is fun\",\n",
        "        \"vector symbolic architectures are powerful\",\n",
        "        \"encoding words into hyperspace\",\n",
        "        \"memory augmented networks love clean data\",\n",
        "    ]\n",
        "    frs_raw = [\n",
        "        \"le calcul hyperdimensionnel est amusant\",\n",
        "        \"les architectures symboliques vectorielles sont puissantes\",\n",
        "        \"encoder des mots dans l'hyperspace\",\n",
        "        \"les réseaux augmentés de mémoire aiment les données propres\",\n",
        "    ]\n",
        "\n",
        "enc_sample_size = min(10_000, len(ens_raw))\n",
        "mem_sample_size = min(10_000, len(ens_raw))\n",
        "ens_sample = ens_raw[:enc_sample_size]\n",
        "frs_sample = frs_raw[:enc_sample_size]\n",
        "print(f\"ENC sample size: {enc_sample_size}\")\n",
        "print(f\"MEM sample size: {mem_sample_size}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Encodage ENC (M5–M7)\n",
        "# ----------------------------\n",
        "D = 8192\n",
        "n = 5\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "Lex_en = m4.M4_LexEN_new(seed=1, D=D)\n",
        "Lex_fr = m4.M4_LexEN_new(seed=2, D=D)\n",
        "pi = rng.permutation(D).astype(np.int64)\n",
        "\n",
        "encoded_en = enc_pipeline.encode_corpus_ENC(ens_sample, Lex_en, pi, D, n, seg_seed0=999)\n",
        "encoded_fr = enc_pipeline.encode_corpus_ENC(frs_sample, Lex_fr, pi, D, n, seg_seed0=1999)\n",
        "\n",
        "E_list_en = [segment[\"E_seq\"] for segment in encoded_en]\n",
        "H_list_en = [segment[\"H\"] for segment in encoded_en]\n",
        "print(f\"Encoded {len(encoded_en)} sentences; signature shape = {H_list_en[0].shape}\")\n",
        "\n",
        "# Quelques stats ENC\n",
        "s_intra, s_inter = enc_pipeline.intra_inter_ngram_sims(E_list_en, D)\n",
        "inter_seg = enc_pipeline.inter_segment_similarity(H_list_en)\n",
        "maj_curves = enc_pipeline.majority_error_curve(E_list_en, pi, D, eta_list=(0.0, 0.05))\n",
        "print(f\"intra={s_intra:.4f}, inter(abs)={s_inter:.4f}, inter segments={inter_seg:.4f}\")\n",
        "print(\"majority curve (eta=0):\", maj_curves[0.0][:2])\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2) Helpers de \"contenu\" (sans K_s) pour fabriquer les paires\n",
        "#    -> on somme des X_t (déjà alignés par Pi^Δ), puis on seuillle\n",
        "# -------------------------------------------------------------\n",
        "def content_signature_from_Xseq(X_seq, majority: str = \"strict\"):\n",
        "    if not X_seq:\n",
        "        raise ValueError(\"X_seq vide\")\n",
        "    S = np.zeros((X_seq[0].shape[0],), dtype=np.int32)\n",
        "    for x in X_seq:\n",
        "        S += x.astype(np.int32, copy=False)\n",
        "    if majority == \"strict\":\n",
        "        return np.where(S >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    elif majority == \"unbiased\":\n",
        "        return np.where(S >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    else:\n",
        "        raise ValueError(\"majority must be 'strict' or 'unbiased'\")\n",
        "\n",
        "def span_signatures_from_trace(X_seq, win: int = 12, stride: int = 6, majority: str = \"unbiased\"):\n",
        "    if not X_seq:\n",
        "        return []\n",
        "    T = len(X_seq)\n",
        "    out = []\n",
        "    if T <= win:\n",
        "        out.append(content_signature_from_Xseq(X_seq, majority))\n",
        "        return out\n",
        "    for start in range(0, T - win + 1, max(1, stride)):\n",
        "        stop = start + win\n",
        "        out.append(content_signature_from_Xseq(X_seq[start:stop], majority))\n",
        "    return out\n",
        "\n",
        "def build_mem_pairs_from_encoded(encoded_en, encoded_fr, win=8, stride=4, majority=\"strict\", max_pairs=None):\n",
        "    pairs = []\n",
        "    N = min(len(encoded_en), len(encoded_fr))\n",
        "    for i in range(N):\n",
        "        X_en = encoded_en[i][\"X_seq\"]\n",
        "        X_fr = encoded_fr[i][\"X_seq\"]\n",
        "        spans_en = span_signatures_from_trace(X_en, win=win, stride=stride, majority=majority)\n",
        "        spans_fr = span_signatures_from_trace(X_fr, win=win, stride=stride, majority=majority)\n",
        "        L = min(len(spans_en), len(spans_fr))\n",
        "        for t in range(L):\n",
        "            pairs.append((\n",
        "                spans_en[t].astype(np.int8, copy=False),\n",
        "                spans_fr[t].astype(np.int8, copy=False),\n",
        "            ))\n",
        "            if max_pairs is not None and len(pairs) >= max_pairs:\n",
        "                return pairs\n",
        "    return pairs\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3) Paires MEM = spans EN/FR (contenu, sans K_s)\n",
        "# -------------------------------------------------------------\n",
        "pairs_mem = build_mem_pairs_from_encoded(encoded_en, encoded_fr, win=8, stride=4, majority=\"strict\")\n",
        "print(f\"Pairs available for MEM training: {len(pairs_mem)}\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 4) Instanciation MEM et entraînement one-pass\n",
        "#    (k ≈ log2(B) + marge ; ici B=256, k=24 convient)\n",
        "# -------------------------------------------------------------\n",
        "MEM_K = 16\n",
        "MEM_BUCKETS = 128\n",
        "cfg = mem_pipeline.MemConfig(D=D, B=MEM_BUCKETS, k=MEM_K, seed_lsh=10, seed_gmem=11)\n",
        "comp = mem_pipeline.make_mem_pipeline(cfg)\n",
        "mem_pipeline.train_one_pass_MEM(comp, pairs_mem)\n",
        "print(\"Training complete; few bucket counts:\", comp.mem.n[:64])\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 5) Probe correcte : on interroge avec Z_en (span) et on compare\n",
        "#    le prototype choisi à Z_fr (span) correspondant\n",
        "# -------------------------------------------------------------\n",
        "probe_count = min(200, len(pairs_mem))\n",
        "sim_values = []\n",
        "for Z_en_vec, Z_fr_vec in tqdm(pairs_mem[:probe_count]):\n",
        "    bucket_idx, score = mem_pipeline.infer_map_top1(comp, Z_en_vec)  # Z_en (span), pas H_en\n",
        "    prototype = comp.mem.H[bucket_idx].astype(np.int32, copy=False)\n",
        "    sim = float(np.dot(prototype, Z_fr_vec.astype(np.int32, copy=False)) / D)\n",
        "    sim_values.append(sim)\n",
        "\n",
        "print(f\"Top-1 mean similarity over {probe_count} span-probes: {np.mean(sim_values):.4f}\")\n",
        "print(f\"Top-1 median similarity: {np.median(sim_values):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3c82ab18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pop mean/median/min/max/std: 296.625 293.0 216 477 39.670714954485\n",
            "p90/p99: 345 394\n"
          ]
        }
      ],
      "source": [
        "nb = comp.mem.n\n",
        "print(\"pop mean/median/min/max/std:\",\n",
        "      float(nb.mean()), float(np.median(nb)), int(nb.min()), int(nb.max()), float(nb.std()))\n",
        "print(\"p90/p99:\", int(np.quantile(nb, 0.90)), int(np.quantile(nb, 0.99)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45bad5ba",
      "metadata": {},
      "source": [
        "\n",
        "> ℹ️ **Remarque pratique** : si le téléchargement OPUS échoue (exécution hors-ligne),\n",
        "> le notebook bascule automatiquement sur un mini corpus embarqué afin de\n",
        "> conserver une démonstration reproductible des blocs ENC et MEM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a979536",
      "metadata": {},
      "source": [
        "# DEC"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78cd5622",
      "metadata": {},
      "source": [
        "## DEC-0 : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52158548",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, logging\n",
        "log = logging.getLogger(\"DEC\")\n",
        "if not log.handlers:\n",
        "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "def sign_strict_pm1(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Retourne int8 dans {-1,+1}; convention 0 -> +1 (majorité stricte).\"\"\"\n",
        "    y = (x >= 0).astype(np.int8, copy=False)  # 0/1\n",
        "    return ((y << 1) - 1).astype(np.int8, copy=False)\n",
        "\n",
        "def hd_assert_pm1(x: np.ndarray, D: int | None = None) -> None:\n",
        "    assert x.dtype == np.int8 and np.all((x == 1) | (x == -1)), \"Vecteur non binaire ±1/int8\"\n",
        "    if D is not None:\n",
        "        assert x.ndim == 1 and x.shape[0] == D, \"Dimension inattendue\"\n",
        "\n",
        "def hd_bind(x: np.ndarray, key: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Binding Hadamard en int8 (produit élémentaire).\"\"\"\n",
        "    return (x.astype(np.int8, copy=False) * key.astype(np.int8, copy=False)).astype(np.int8, copy=False)\n",
        "\n",
        "def hd_sim(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    \"\"\"Similarité cosinus sur ±1 (équivalente à corrélation normalisée).\"\"\"\n",
        "    assert x.shape == y.shape\n",
        "    return float((x.astype(np.int32) @ y.astype(np.int32)) / x.shape[0])\n",
        "\n",
        "def permute_pow(x: np.ndarray, pi: np.ndarray, power: int) -> np.ndarray:\n",
        "    \"\"\"Applique Π^power via indices précalculés si fournis (sinon compose).\"\"\"\n",
        "    idx = np.arange(x.shape[0], dtype=np.int64)\n",
        "    for _ in range(power % x.shape[0]):\n",
        "        idx = pi[idx]\n",
        "    return x[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "22094d40",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ---------------------------\n",
        "# Helpers (cf. DD0 du tutoriel)\n",
        "# ---------------------------\n",
        "def hd_assert_pm1(x: np.ndarray, D: int | None = None) -> None:\n",
        "    assert x.dtype == np.int8 and np.all((x == 1) | (x == -1)), \"expect ±1/int8\"\n",
        "    if D is not None:\n",
        "        assert x.ndim == 1 and x.shape[0] == D, \"wrong shape\"\n",
        "\n",
        "def hd_bind(x: np.ndarray, key: np.ndarray) -> np.ndarray:\n",
        "    return (x.astype(np.int8, copy=False) * key.astype(np.int8, copy=False)).astype(np.int8, copy=False)\n",
        "\n",
        "def hd_sim(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    assert x.shape == y.shape\n",
        "    # produit scalaire en int32 pour stabilité, renvoyé en float64 (double précision)\n",
        "    return float((x.astype(np.int32) @ y.astype(np.int32)) / x.shape[0])\n",
        "\n",
        "def pm1(shape, rng) -> np.ndarray:\n",
        "    \"\"\"Tire des vecteurs Rademacher ±1 en int8, shape=(...), dtype=int8.\"\"\"\n",
        "    return (2 * rng.integers(0, 2, size=shape, dtype=np.int8) - 1).astype(np.int8, copy=False)\n",
        "\n",
        "# ---------------------------\n",
        "# DX0: tests\n",
        "# ---------------------------\n",
        "def dx0_sanity(D: int = 16_384, N_sim: int = 1_000, seed: int = 2024, tol: float = 5e-3) -> None:\n",
        "    \"\"\"\n",
        "    Vérifie:\n",
        "      1) hd_sim(x,x)=1 et hd_sim(x,-x)=-1 (à tol près)\n",
        "      2) Invariance de similarité par binding: sim(x,y)=sim(x⊗k, y⊗k)\n",
        "      3) Préservation de la norme (||x||_2/√D = 1) avant/après binding\n",
        "    Critère d'acceptation (CA): écarts absolus ≤ 5e-3.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    max_err_self = 0.0\n",
        "    max_err_neg  = 0.0\n",
        "    max_err_bind = 0.0\n",
        "    max_err_norm = 0.0\n",
        "\n",
        "    for _ in range(N_sim):\n",
        "        x = pm1(D, rng); y = pm1(D, rng); k = pm1(D, rng)\n",
        "        hd_assert_pm1(x, D); hd_assert_pm1(y, D); hd_assert_pm1(k, D)\n",
        "\n",
        "        # (1) Identités de similarité\n",
        "        s_xx = hd_sim(x, x)\n",
        "        s_xnx = hd_sim(x, (-x).astype(np.int8, copy=False))\n",
        "\n",
        "        max_err_self = max(max_err_self, abs(s_xx - 1.0))\n",
        "        max_err_neg  = max(max_err_neg,  abs(s_xnx + 1.0))\n",
        "\n",
        "        # (2) Invariance par binding (DEC1)\n",
        "        s_xy      = hd_sim(x, y)\n",
        "        xk, yk    = hd_bind(x, k), hd_bind(y, k)\n",
        "        s_xy_bind = hd_sim(xk, yk)\n",
        "        max_err_bind = max(max_err_bind, abs(s_xy - s_xy_bind))\n",
        "\n",
        "        # (3) Normes (avant/après binding)\n",
        "        # Pour des vecteurs ±1, ||x||_2 = sqrt(D). On vérifie la normalisation relative.\n",
        "        norm_x  = np.linalg.norm(x.astype(np.float64)) / np.sqrt(D)\n",
        "        norm_xk = np.linalg.norm(xk.astype(np.float64)) / np.sqrt(D)\n",
        "        max_err_norm = max(max_err_norm, abs(norm_x - 1.0), abs(norm_xk - 1.0))\n",
        "\n",
        "    # Rapport\n",
        "    print(\"DX0 — Sanity checks (double précision)\")\n",
        "    print(f\"  D={D}, N={N_sim}, tol={tol:.1e}\")\n",
        "    print(f\"  max|sim(x,x)-1|         = {max_err_self:.3e}\")\n",
        "    print(f\"  max|sim(x,-x)+1|        = {max_err_neg:.3e}\")\n",
        "    print(f\"  max|sim(x,y)-sim(x⊗k,y⊗k)| = {max_err_bind:.3e}\")\n",
        "    print(f\"  max| ||x||/√D - 1 | (incl. bind) = {max_err_norm:.3e}\")\n",
        "\n",
        "    # Assertions CA\n",
        "    assert max_err_self <= tol,     \"CA non satisfait: sim(x,x) s'écarte de 1\"\n",
        "    assert max_err_neg  <= tol,     \"CA non satisfait: sim(x,-x) s'écarte de -1\"\n",
        "    assert max_err_bind <= tol,     \"CA non satisfait: invariance de similarité après binding\"\n",
        "    assert max_err_norm <= tol,     \"CA non satisfait: norme non préservée (relative)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c12ada1b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DX0 — Sanity checks (double précision)\n",
            "  D=16384, N=1000, tol=5.0e-03\n",
            "  max|sim(x,x)-1|         = 0.000e+00\n",
            "  max|sim(x,-x)+1|        = 0.000e+00\n",
            "  max|sim(x,y)-sim(x⊗k,y⊗k)| = 0.000e+00\n",
            "  max| ||x||/√D - 1 | (incl. bind) = 0.000e+00\n"
          ]
        }
      ],
      "source": [
        "dx0_sanity()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b4826d",
      "metadata": {},
      "source": [
        "## DD1 .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "02ebc2a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DD1_ctx(Hs: np.ndarray, G_DEC: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Q^(s) = H^(s) ⊗ G_DEC, binding isométrique (int8 -> int8).\n",
        "    \"\"\"\n",
        "    assert Hs.dtype == np.int8 and G_DEC.dtype == np.int8\n",
        "    hd_assert_pm1(Hs); hd_assert_pm1(G_DEC, Hs.shape[0])\n",
        "    return hd_bind(Hs, G_DEC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4cc32465",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DX1 — DD1_ctx (isométrie & contrats)\n",
            "  D=16384, m=64, trials=200, tol=5.0e-03\n",
            "  max|sim_before - sim_after|  = 0.000e+00\n",
            "  max| ||H||/√D - 1 | (incl. bind) = 0.000e+00\n",
            "  max|Gram_before - Gram_after| = 0.000e+00\n"
          ]
        }
      ],
      "source": [
        "# --- DX1: tests détaillés ---\n",
        "def dx1_test_DD1_ctx(D: int = 16_384, m: int = 64, trials: int = 200, seed: int = 1234, tol: float = 5e-3):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # 1) Similarité inchangée et normes préservées (sur 'trials' paires)\n",
        "    max_err_sim = 0.0\n",
        "    max_err_norm = 0.0\n",
        "    for _ in range(trials):\n",
        "        H1, H2, G = pm1(D, rng), pm1(D, rng), pm1(D, rng)\n",
        "        # Copies pour vérifier non-mutation\n",
        "        H1_copy, H2_copy, G_copy = H1.copy(), H2.copy(), G.copy()\n",
        "\n",
        "        Q1, Q2 = DD1_ctx(H1, G), DD1_ctx(H2, G)\n",
        "        # Similarité\n",
        "        s0 = hd_sim(H1, H2)\n",
        "        s1 = hd_sim(Q1, Q2)\n",
        "        max_err_sim = max(max_err_sim, abs(s0 - s1))\n",
        "\n",
        "        # Normes relatives\n",
        "        nH1  = np.linalg.norm(H1.astype(np.float64)) / np.sqrt(D)\n",
        "        nQ1  = np.linalg.norm(Q1.astype(np.float64)) / np.sqrt(D)\n",
        "        nH2  = np.linalg.norm(H2.astype(np.float64)) / np.sqrt(D)\n",
        "        nQ2  = np.linalg.norm(Q2.astype(np.float64)) / np.sqrt(D)\n",
        "        max_err_norm = max(max_err_norm, abs(nH1 - 1.0), abs(nQ1 - 1.0),\n",
        "                                           abs(nH2 - 1.0), abs(nQ2 - 1.0))\n",
        "\n",
        "        # Contrats: dtype & non-mutation\n",
        "        assert Q1.dtype == np.int8 and Q2.dtype == np.int8\n",
        "        assert np.all(H1 == H1_copy) and np.all(H2 == H2_copy) and np.all(G == G_copy), \"mutation détectée\"\n",
        "        assert np.all((Q1 == 1) | (Q1 == -1)) and np.all((Q2 == 1) | (Q2 == -1)), \"sortie hors ±1\"\n",
        "\n",
        "    # 2) Isométrie de Gram (m vecteurs)\n",
        "    H = np.stack([pm1(D, rng) for _ in range(m)], axis=0)  # (m, D) ±1/int8\n",
        "    G = pm1(D, rng)\n",
        "    Q = np.stack([DD1_ctx(H[i], G) for i in range(m)], axis=0)\n",
        "\n",
        "    # Gram avant/après, en double précision\n",
        "    G0 = (H.astype(np.int32) @ H.astype(np.int32).T) / D\n",
        "    G1 = (Q.astype(np.int32) @ Q.astype(np.int32).T) / D\n",
        "    max_err_gram = float(np.max(np.abs(G0.astype(np.float64) - G1.astype(np.float64))))\n",
        "\n",
        "    # --- Rapport ---\n",
        "    print(\"DX1 — DD1_ctx (isométrie & contrats)\")\n",
        "    print(f\"  D={D}, m={m}, trials={trials}, tol={tol:.1e}\")\n",
        "    print(f\"  max|sim_before - sim_after|  = {max_err_sim:.3e}\")\n",
        "    print(f\"  max| ||H||/√D - 1 | (incl. bind) = {max_err_norm:.3e}\")\n",
        "    print(f\"  max|Gram_before - Gram_after| = {max_err_gram:.3e}\")\n",
        "\n",
        "    # --- Critères d'acceptation ---\n",
        "    assert max_err_sim  <= tol, \"Invariance de similarité violée (DEC1)\"\n",
        "    assert max_err_norm <= tol, \"Norme non préservée (relative)\"\n",
        "    assert max_err_gram <= tol, \"Isométrie de Gram violée (DEC1)\"\n",
        "\n",
        "dx1_test_DD1_ctx()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ebe1921",
      "metadata": {},
      "source": [
        "# DD2 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f4e780",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:36: SyntaxWarning: invalid escape sequence '\\h'\n",
            "<>:36: SyntaxWarning: invalid escape sequence '\\h'\n",
            "/var/folders/zg/w26r16bd5c11s4xr1f6lb4mh0000gn/T/ipykernel_74953/515701960.py:36: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  H_hist = sign( sum_{j=1..ell} Pi^j L_fr(\\hat v_{t-j}) ).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import logging\n",
        "from typing import List, Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "log = logging.getLogger(\"DEC.DX2.v2\")\n",
        "\n",
        "# -- utilitaires (identiques à DD0) --\n",
        "def sign_strict_pm1(x: np.ndarray) -> np.ndarray:\n",
        "    y = (x >= 0).astype(np.int8, copy=False)\n",
        "    return ((y << 1) - 1).astype(np.int8, copy=False)\n",
        "\n",
        "def hd_assert_pm1(x: np.ndarray, D: int | None = None) -> None:\n",
        "    assert x.dtype == np.int8 and np.all((x == 1) | (x == -1)), \"±1/int8 attendu\"\n",
        "    if D is not None:\n",
        "        assert x.ndim == 1 and x.shape[0] == D, \"shape inattendu\"\n",
        "\n",
        "def permute_pow(x: np.ndarray, pi: np.ndarray, power: int) -> np.ndarray:\n",
        "    # NOTE: pour la perf réelle, pré-calculer pi_pows ; ici: version simple et sûre.\n",
        "    idx = np.arange(x.shape[0], dtype=np.int64)\n",
        "    for _ in range(power % x.shape[0]):\n",
        "        idx = pi[idx]\n",
        "    return x[idx]\n",
        "\n",
        "def hd_sim(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    return float((x.astype(np.int32) @ y.astype(np.int32)) / x.shape[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "326e389d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_perm_inverse(pi: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Construit l'inverse de la permutation pi (ndarray d'indices).\"\"\"\n",
        "    assert isinstance(pi, np.ndarray) and pi.ndim == 1\n",
        "    pi_inv = np.empty_like(pi)\n",
        "    pi_inv[pi] = np.arange(pi.shape[0], dtype=pi.dtype)\n",
        "    return pi_inv\n",
        "\n",
        "def permute_pow_signed(x: np.ndarray, pi: np.ndarray, pi_inv: np.ndarray, power: int) -> np.ndarray:\n",
        "    r\"\"\"\n",
        "    Applique Π^power sur x (±1/int8) avec gestion des puissances négatives via Π^{-1}.\n",
        "    - Complexity OK ici car |power| ≤ ell (≤ 8 dans DX2).\n",
        "    - Pour de grands exponents, préférer pré-calcul d'un tableau pi_pows.\n",
        "    \"\"\"\n",
        "    assert x.ndim == 1 and x.shape[0] == pi.shape[0] == pi_inv.shape[0]\n",
        "    if power == 0:\n",
        "        return x\n",
        "    idx = np.arange(x.shape[0], dtype=np.int64)\n",
        "    if power > 0:\n",
        "        for _ in range(power):\n",
        "            idx = pi[idx]\n",
        "    else:\n",
        "        for _ in range(-power):\n",
        "            idx = pi_inv[idx]\n",
        "    return x[idx].astype(np.int8, copy=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8a257745",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DD2_query(Qs: np.ndarray,\n",
        "              hist_tokens: list[np.ndarray],  # vecteurs L_fr(\\hat v)\n",
        "              pi: np.ndarray,\n",
        "              alpha: float, beta: float,\n",
        "              ell: int) -> np.ndarray:\n",
        "    r\"\"\"R_t = α Qs + β * sign( sum_{j=1..ell} Π^j L_{t-j} ), normalisé.\"\"\"\n",
        "    D = Qs.shape[0]\n",
        "    pi_inv = build_perm_inverse(pi)\n",
        "    # positionnement historique\n",
        "    shifted = [permute_pow_signed(hist_tokens[j], pi, pi_inv, j+1) for j in range(ell)]\n",
        "    H_hist = np.sum(np.stack(shifted, axis=0).astype(np.int16), axis=0)\n",
        "    H_hist = ((H_hist >= 0).astype(np.int8) * 2 - 1).astype(np.int8)  # sign strict\n",
        "    # combinaison et normalisation\n",
        "    Rt = alpha*Qs.astype(np.float64) + beta*H_hist.astype(np.float64)\n",
        "    Rt = Rt / np.linalg.norm(Rt) * np.sqrt(D)\n",
        "    return Rt.astype(np.float64)\n",
        "\n",
        "def DX2_run():\n",
        "    D, trials = 16384, 200\n",
        "    ells = (2,4,8); ratios = (1/3, 1.0, 3.0)\n",
        "    g = np.random.default_rng(2025)\n",
        "    pi = np.arange(D, dtype=np.int64); g.shuffle(pi)\n",
        "    pi_inv = build_perm_inverse(pi)\n",
        "\n",
        "    def rand_pm1():\n",
        "        r = g.integers(0, 2, size=D, dtype=np.int8)\n",
        "        return ((r << 1) - 1).astype(np.int8, copy=False)\n",
        "\n",
        "    def sim(a,b): return float((a.astype(np.int32) @ b.astype(np.int32)) / D)\n",
        "\n",
        "    norms = {}\n",
        "    gram_uniform_ok = True\n",
        "    pair_shift_ok = True\n",
        "\n",
        "    for ell in tqdm(ells):\n",
        "        for r in ratios:\n",
        "            alpha, beta = r, 1.0\n",
        "            vals = []\n",
        "            for _ in range(trials):\n",
        "                Qs   = rand_pm1()\n",
        "                hist = [rand_pm1() for _ in range(ell)]\n",
        "                P = np.stack([permute_pow_signed(hist[j], pi, pi_inv, j+1) for j in range(ell)], axis=0)\n",
        "\n",
        "                # (i) invariance Gram sous permutation uniforme\n",
        "                s = int(g.integers(1, 7))\n",
        "                P_uni = np.stack([permute_pow_signed(P[j], pi, pi_inv, s) for j in range(ell)], axis=0)\n",
        "                G  = (P.astype(np.int32) @ P.T.astype(np.int32)) / D\n",
        "                Gu = (P_uni.astype(np.int32) @ P_uni.T.astype(np.int32)) / D\n",
        "                if not np.allclose(G, Gu, atol=5e-3, rtol=0):\n",
        "                    gram_uniform_ok = False\n",
        "\n",
        "                # (ii) identité paire-à-paire: <Π^i Li, Π^k Lk> == <Li, Π^{k-i} Lk>\n",
        "                for i in range(ell):\n",
        "                    for k in range(ell):\n",
        "                        lhs = sim(P[i], P[k])\n",
        "                        rhs = sim(hist[i], permute_pow_signed(hist[k], pi, pi_inv, (k+1)-(i+1)))\n",
        "                        if abs(lhs - rhs) > 5e-3:\n",
        "                            pair_shift_ok = False\n",
        "                            break\n",
        "\n",
        "                # (iii) norme de R_t\n",
        "                Rt = DD2_query(Qs, hist, pi, alpha=alpha, beta=beta, ell=ell)\n",
        "                vals.append(float(np.linalg.norm(Rt) / np.sqrt(D)))\n",
        "\n",
        "            norms[(ell, r)] = (min(vals), float(np.median(vals)), max(vals))\n",
        "\n",
        "    # reporting\n",
        "    import logging\n",
        "    log = logging.getLogger(\"DX2\")\n",
        "    if not log.handlers:\n",
        "        logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "    log.info(\"DX2 — Norme(R_t)/sqrt(D) par (ell, alpha/beta): min | median | max\")\n",
        "    for (ell, r), (mn, md, mx) in sorted(norms.items()):\n",
        "        log.info(\"  ell=%d, alpha/beta=%.3g  ->  %.3f | %.3f | %.3f\", ell, r, mn, md, mx)\n",
        "\n",
        "    # CA\n",
        "    in_band = all(0.9 <= s <= 1.1 for stats in norms.values() for s in stats)\n",
        "    assert in_band, \"DX2: norme(R_t)/sqrt(D) hors bande [0.9,1.1].\"\n",
        "    assert gram_uniform_ok, \"DX2: Gram NON invariant sous permutation uniforme.\"\n",
        "    assert pair_shift_ok, \"DX2: identité de décalage paire-à-paire violée.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4e4acc1e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:06<00:00,  2.21s/it]\n",
            "2025-10-06 10:41:53,673 [INFO] DX2 — Norme(R_t)/sqrt(D) par (ell, alpha/beta): min | median | max\n",
            "2025-10-06 10:41:53,673 [INFO]   ell=2, alpha/beta=0.333  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,673 [INFO]   ell=2, alpha/beta=1  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=2, alpha/beta=3  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=4, alpha/beta=0.333  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=4, alpha/beta=1  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=4, alpha/beta=3  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=8, alpha/beta=0.333  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=8, alpha/beta=1  ->  1.000 | 1.000 | 1.000\n",
            "2025-10-06 10:41:53,674 [INFO]   ell=8, alpha/beta=3  ->  1.000 | 1.000 | 1.000\n"
          ]
        }
      ],
      "source": [
        "DX2_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d999ef",
      "metadata": {},
      "source": [
        "# DD3 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "871f3897",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DD3_bindToMem(Rt: np.ndarray, G_MEM: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"~R_t = R_t ⊗ G_MEM (int8 -> int8).\"\"\"\n",
        "    hd_assert_pm1(Rt); hd_assert_pm1(G_MEM, Rt.shape[0])\n",
        "    return hd_bind(Rt, G_MEM)\n",
        "\n",
        "def hd_sim_dot(x: np.ndarray, y: np.ndarray) -> int:\n",
        "    \"\"\"Produit scalaire entier (évite l'arrondi); x,y en int8 ±1.\"\"\"\n",
        "    return int(x.astype(np.int32) @ y.astype(np.int32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f40787be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- test KS (asymptotique) sans dépendance externe ---\n",
        "def ks_2samp_asymp(x: np.ndarray, y: np.ndarray) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    KS à 2 échantillons: renvoie (D_stat, pval approx).\n",
        "    Correctifs:\n",
        "      - si D_stat == 0 => p = 1.0 (distributions identiques)\n",
        "      - clamp numérique sur lambda pour petits D_stat\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    y = np.asarray(y, dtype=np.float64)\n",
        "    n, m = x.size, y.size\n",
        "    x_sorted = np.sort(x); y_sorted = np.sort(y)\n",
        "    i = j = 0\n",
        "    cdf_x = cdf_y = 0.0\n",
        "    D_stat = 0.0\n",
        "    while i < n and j < m:\n",
        "        if x_sorted[i] < y_sorted[j]:\n",
        "            cdf_x = (i + 1) / n; i += 1\n",
        "        elif x_sorted[i] > y_sorted[j]:\n",
        "            cdf_y = (j + 1) / m; j += 1\n",
        "        else:\n",
        "            v = x_sorted[i]\n",
        "            while i < n and x_sorted[i] == v: i += 1\n",
        "            while j < m and y_sorted[j] == v: j += 1\n",
        "            cdf_x = i / n; cdf_y = j / m\n",
        "        D_stat = max(D_stat, abs(cdf_x - cdf_y))\n",
        "    if i < n: D_stat = max(D_stat, abs(1.0 - (j / m)))\n",
        "    if j < m: D_stat = max(D_stat, abs(1.0 - (i / n)))\n",
        "\n",
        "    # --- Correctif dégénéré ---\n",
        "    if D_stat == 0.0:\n",
        "        return 0.0, 1.0\n",
        "\n",
        "    en = np.sqrt(n * m / (n + m))\n",
        "    lam = (en + 0.12 + 0.11 / max(en, 1e-12)) * D_stat\n",
        "    # Pour très petits \"lam\", la série tend vers 1 => borne supérieure 1.0\n",
        "    if lam < 1e-8:\n",
        "        return float(D_stat), 1.0\n",
        "\n",
        "    # Évaluation de la série alternée (tronquée) avec coupe stricte dans [0,1]\n",
        "    terms = [np.exp(-2.0 * (k**2) * (lam**2)) for k in range(1, 201)]\n",
        "    pval = 2.0 * sum(((-1)**(k-1)) * terms[k-1] for k in range(1, len(terms)+1))\n",
        "    pval = float(max(0.0, min(1.0, pval)))\n",
        "    return float(D_stat), pval\n",
        "\n",
        "# --- campagne DX3 ---\n",
        "def DX3_run(D: int = 16384, C: int = 500, T: int = 200, seed: int = 2025,\n",
        "            rel_tol: float = 0.01, pmin: float = 0.10) -> None:\n",
        "    \"\"\"\n",
        "    D: dimension; C: #protos mémoire; T: #requêtes; rel_tol: seuil d'écart relatif moyen; pmin: seuil KS.\n",
        "    \"\"\"\n",
        "    g = np.random.default_rng(seed)\n",
        "\n",
        "    # Génère clés et banques en ±1/int8\n",
        "    def rand_pm1(size: int) -> np.ndarray:\n",
        "        r = g.integers(0, 2, size=size, dtype=np.int8)\n",
        "        return ((r << 1) - 1).astype(np.int8, copy=False)\n",
        "\n",
        "    G_MEM = rand_pm1(D)\n",
        "    M_bank = np.stack([rand_pm1(D) for _ in range(C)], axis=0)   # (C, D), int8\n",
        "    Q_batch = np.stack([rand_pm1(D) for _ in range(T)], axis=0)  # (T, D), int8\n",
        "\n",
        "    # Scores \"dans la tranche mémoire\" vs \"débindés\"\n",
        "    #   S_mem[t,c]   = < Rt⊗G_MEM , M_c >\n",
        "    #   S_unbd[t,c]  = < Rt , M_c⊗G_MEM >\n",
        "    S_mem  = np.zeros((T, C), dtype=np.int32)\n",
        "    S_unbd = np.zeros((T, C), dtype=np.int32)\n",
        "\n",
        "    for t in range(T):\n",
        "        Rt = Q_batch[t]\n",
        "        Rt_mem = DD3_bindToMem(Rt, G_MEM)            # Rt ⊗ G_MEM\n",
        "        for c in range(C):\n",
        "            Mc = M_bank[c]\n",
        "            S_mem[t, c]  = hd_sim_dot(Rt_mem, Mc)\n",
        "            S_unbd[t, c] = hd_sim_dot(Rt, hd_bind(Mc, G_MEM))\n",
        "\n",
        "    # a) Erreur relative moyenne (sur tous les scores)\n",
        "    A = S_mem.astype(np.float64).ravel()\n",
        "    B = S_unbd.astype(np.float64).ravel()\n",
        "    denom = np.maximum(1.0, np.abs(B))               # évite division par 0\n",
        "    rel_err = np.abs(A - B) / denom\n",
        "    rel_err_mean = float(np.mean(rel_err))\n",
        "\n",
        "    # b) Test KS sur distributions aplaties\n",
        "    D_stat, pval = ks_2samp_asymp(A, B)\n",
        "\n",
        "    # Reporting\n",
        "    log.info(\"DX3 — Invariance (dé)binding mémoire\")\n",
        "    log.info(\"  D=%d, C=%d, T=%d\", D, C, T)\n",
        "    log.info(\"  Erreur relative moyenne  = %.6f\", rel_err_mean)\n",
        "    log.info(\"  KS: D=%.6f, p=%.3f\", D_stat, pval)\n",
        "\n",
        "    # CA\n",
        "    assert rel_err_mean <= rel_tol, f\"DX3: erreur relative moyenne {rel_err_mean:.4f} > {rel_tol}\"\n",
        "    assert pval > pmin, f\"DX3: p-value KS {pval:.3f} ≤ {pmin:.2f}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "c21c01a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-06 10:54:12,268 [INFO] DX3 — Invariance (dé)binding mémoire\n",
            "2025-10-06 10:54:12,268 [INFO]   D=16384, C=500, T=200\n",
            "2025-10-06 10:54:12,268 [INFO]   Erreur relative moyenne  = 0.000000\n",
            "2025-10-06 10:54:12,268 [INFO]   KS: D=0.000000, p=1.000\n"
          ]
        }
      ],
      "source": [
        "DX3_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb3d23c",
      "metadata": {},
      "source": [
        "# DD4 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "c549139a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DD4_search_topK(Rt_tilde: np.ndarray, prototypes: np.ndarray, K: int) -> tuple[int, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    prototypes: array shape (B, D) en int8 (±1) pour M_c seuillés ou non seuillés normalisés.\n",
        "    Retour: (c_star, C_K, scores_CK)\n",
        "    \"\"\"\n",
        "    D = Rt_tilde.shape[0]\n",
        "    assert prototypes.ndim == 2 and prototypes.shape[1] == D and prototypes.dtype == np.int8\n",
        "    # Produits scalaires stables\n",
        "    scores = (prototypes.astype(np.int32) @ Rt_tilde.astype(np.int32)).astype(np.int32)  # (B,)\n",
        "    K = min(K, scores.shape[0])\n",
        "    idx = np.argpartition(scores, -K)[-K:]\n",
        "    top_order = idx[np.argsort(scores[idx])[::-1]]\n",
        "    c_star = int(top_order[0])\n",
        "    return c_star, top_order, scores[top_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "48850b8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DX4_run(D: int = 16384, B: int = 10000, trials: int = 200, \n",
        "            Ks=(100, 500, 2000), seed: int = 0) -> dict[int, float]:\n",
        "    \"\"\"\n",
        "    Mesure empirique du rappel de c* parmi les top-K prototypes.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    recalls = {K: 0 for K in Ks}\n",
        "    for _ in range(trials):\n",
        "        # Génère B prototypes ±1 (int8)\n",
        "        prototypes = rng.choice([-1, 1], size=(B, D))\n",
        "        prototypes = prototypes.astype(np.int8)\n",
        "        # Choisit une classe cible c*\n",
        "        c_star = rng.integers(0, B)\n",
        "        Rt = prototypes[c_star].copy()\n",
        "        # Appel au module DD4\n",
        "        _, C_K, _ = DD4_search_topK(Rt, prototypes, max(Ks))\n",
        "        for K in Ks:\n",
        "            if c_star in C_K[:K]:\n",
        "                recalls[K] += 1\n",
        "    # Moyenne\n",
        "    return {K: recalls[K]/trials for K in Ks}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "2e3dea67",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{100: 1.0, 500: 1.0, 2000: 1.0}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DX4_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b943256",
      "metadata": {},
      "source": [
        "# DD5 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "bff951c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DD5_payload(Mc: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Mc: prototype non seuillé (int16/int32) OU déjà binaire int8.\n",
        "    Renvoie Z_hat en int8 (±1).\n",
        "    \"\"\"\n",
        "    if Mc.dtype == np.int8:\n",
        "        hd_assert_pm1(Mc)\n",
        "        return Mc\n",
        "    return sign_strict_pm1(Mc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e44670a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DX5_run(D: int = 16384, trials: int = 200, ms=(4, 8, 16), seed: int = 0):\n",
        "    \"\"\"\n",
        "    Mesure l’exactitude binaire en fonction du nombre m_{c*}.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    accuracies = {}\n",
        "    for m in ms:\n",
        "        accs = []\n",
        "        for _ in range(trials):\n",
        "            # Vecteur de référence\n",
        "            ref = rng.choice([-1, 1], size=D).astype(np.int8)\n",
        "            # Accumulation de m copies bruitées\n",
        "            acc = np.zeros(D, dtype=np.int32)\n",
        "            for _ in range(m):\n",
        "                acc += ref\n",
        "            # Seuillage\n",
        "            Z_hat = DD5_payload(acc)\n",
        "            # Exactitude binaire\n",
        "            accs.append(np.mean(Z_hat == ref))\n",
        "        accuracies[m] = float(np.mean(accs))\n",
        "    return accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "cdb3df09",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{4: 1.0, 8: 1.0, 16: 1.0}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DX5_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa074d57",
      "metadata": {},
      "source": [
        "# DD6 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ff4980",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def DD6_vote(\n",
        "#     Z_hat: np.ndarray,\n",
        "#     H_LM: np.ndarray,\n",
        "#     L_fr,\n",
        "#     cand_vocab: list[str],\n",
        "#     lam: float = 0.0\n",
        "# ) -> tuple[str, np.ndarray]:\n",
        "#     \"\"\"\n",
        "#     Renvoie (token*, scores) sur cand_vocab.\n",
        "#     \"\"\"\n",
        "#     D = Z_hat.shape[0]\n",
        "#     hd_assert_pm1(Z_hat, D); hd_assert_pm1(H_LM, D)\n",
        "#     scores = []\n",
        "#     for v in cand_vocab:\n",
        "#         Lv = L_fr(v).astype(np.int8, copy=False)\n",
        "#         hd_assert_pm1(Lv, D)\n",
        "#         s = (Z_hat.astype(np.int32) @ Lv.astype(np.int32)) \\\n",
        "#             + lam * (H_LM.astype(np.int32) @ Lv.astype(np.int32))\n",
        "#         scores.append(float(s))\n",
        "#     scores = np.asarray(scores, dtype=np.float32)\n",
        "#     best = int(np.argmax(scores))\n",
        "#     return cand_vocab[best], scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e56642b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ToyLexFR:\n",
        "    def __init__(self, vocab: list[str], D: int, seed: int = 1234):\n",
        "        self.vocab = vocab\n",
        "        self.D = D\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        # table de vecteurs ±1/int8\n",
        "        self.table = {v: self.rng.choice(np.array([-1, 1], dtype=np.int8), size=D) for v in vocab}\n",
        "\n",
        "    def __call__(self, v: str) -> np.ndarray:\n",
        "        return self.table[v]\n",
        "\n",
        "# -- Génération contrôlée de corrélations (flip par coordonnée) ----------------\n",
        "def flip_to_target(vec: np.ndarray, target_sim: float, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Retourne une copie de 'vec' dont la similarité attendue vaut 'target_sim'.\n",
        "    Pour ±1, si p_flip = (1 - target_sim)/2, alors E[sim] = 1 - 2*p_flip = target_sim.\n",
        "    \"\"\"\n",
        "    D = vec.shape[0]\n",
        "    p_flip = max(0.0, min(1.0, (1.0 - float(target_sim)) / 2.0))\n",
        "    mask = (rng.random(D) < p_flip).astype(np.int8)          # 1 si on flippe\n",
        "    flips = (1 - 2 * mask).astype(np.int8, copy=False)       # 1 -> -1, 0 -> +1\n",
        "    out = (vec.astype(np.int8, copy=False) * flips).astype(np.int8, copy=False)\n",
        "    return out\n",
        "\n",
        "# -- Module testé (fourni) ------------------------------------------------------\n",
        "def DD6_vote(\n",
        "    Z_hat: np.ndarray,\n",
        "    H_LM: np.ndarray,\n",
        "    L_fr,\n",
        "    cand_vocab: list[str],\n",
        "    lam: float = 0.0\n",
        ") -> tuple[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Renvoie (token*, scores) sur cand_vocab.\n",
        "    scores[v] = <Z_hat, L_fr(v)> + lam * <H_LM, L_fr(v)>.\n",
        "    \"\"\"\n",
        "    D = Z_hat.shape[0]\n",
        "    hd_assert_pm1(Z_hat, D); hd_assert_pm1(H_LM, D)\n",
        "    scores = []\n",
        "    for v in cand_vocab:\n",
        "        Lv = L_fr(v).astype(np.int8, copy=False)\n",
        "        hd_assert_pm1(Lv, D)\n",
        "        s = (Z_hat.astype(np.int32) @ Lv.astype(np.int32)) \\\n",
        "            + lam * (H_LM.astype(np.int32) @ Lv.astype(np.int32))\n",
        "        scores.append(float(s))\n",
        "    scores = np.asarray(scores, dtype=np.float64)   # précision numerique\n",
        "    best = int(np.argmax(scores))\n",
        "    return cand_vocab[best], scores\n",
        "\n",
        "# -- Perplexité HD: softmax sur scores normalisés par D -------------------------\n",
        "def hd_perplexity(scores: np.ndarray, true_idx: int, D: int, tau: float = 1.0) -> float:\n",
        "    \"\"\"\n",
        "    Perplexité = exp( - log p(true) ), avec p ∝ exp( (scores/D)/tau ).\n",
        "    On divise par D pour éviter des logits trop grands (HD).\n",
        "    \"\"\"\n",
        "    logits = scores / (D * max(1e-6, tau))\n",
        "    logits = logits - np.max(logits)               # stabilité\n",
        "    exps = np.exp(logits)\n",
        "    p = exps / np.sum(exps)\n",
        "    p_true = float(max(p[true_idx], 1e-12))\n",
        "    return float(np.exp(-np.log(p_true)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "587fb688",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b983cd28",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
