{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# explore_bis\n",
        "\n",
        "Notebook de démonstration pour la brique *encoder* désormais packagée dans `hdc_project.encoder`.\n",
        "Nous importons directement les modules M0–M8 depuis `src/` et rejouons les vérifications clés\n",
        "présentes dans `explore.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialisation du chemin `src`\n",
        "\n",
        "On s'assure que `src/` est visible dans `sys.path` afin d'importer le package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src path registered: /Users/aymenmejri/Desktop/MyCode/experiments/hdc_v2/hdc_project/src\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "ROOT = Path.cwd().parent\n",
        "SRC = ROOT / \"src\"\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n",
        "print(f\"src path registered: {SRC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports des modules packagés\n",
        "\n",
        "Les modules numérotés `M0` à `M7` et le pipeline `M8` sont exposés via `hdc_project.encoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from hdc_project.encoder import m0, m1, m2, m3, m4, m5, m6, m7, pipeline\n",
        "import math\n",
        "from typing import Optional, Sequence, Tuple, Any, Dict\n",
        "\n",
        "import time\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vérification statistique de la clé Rademacher (M0 & M1)\n",
        "\n",
        "On vérifie que deux clés indépendantes ont une similarité proche de 0 et que la probabilité de \n",
        "queues est conforme à la borne de Hoeffding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean(sim) = 0.0013\n",
            "P(|sim| > 0.1) = 0.0000e+00 (bound=7.1426e-05)\n"
          ]
        }
      ],
      "source": [
        "D = 2048\n",
        "n_pairs = 800\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "sims = []\n",
        "for _ in range(n_pairs):\n",
        "    J = m0.M0_NewKey(int(rng.integers(0, 2**31 - 1)), D)\n",
        "    Jp = m0.M0_NewKey(int(rng.integers(0, 2**31 - 1)), D)\n",
        "    sims.append(m1.M1_sim(J, Jp))\n",
        "\n",
        "sims = np.asarray(sims)\n",
        "mean_sim = float(sims.mean())\n",
        "tail_prob = float((np.abs(sims) > 0.1).mean())\n",
        "hoeff = 2.0 * np.exp(-D * 0.1**2 / 2.0)\n",
        "\n",
        "print(f\"mean(sim) = {mean_sim:.4f}\")\n",
        "print(f\"P(|sim| > 0.1) = {tail_prob:.4e} (bound={hoeff:.4e})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encodage de phrases avec le pipeline `M8_ENC`\n",
        "\n",
        "On utilise le lexique `M4`, la permutation `M2` et le pipeline `M8` pour encoder quelques phrases,\n",
        "puis on calcule les métriques de validation décrites dans le notebook original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de segments encodés: 3\n",
            "Signature shape: (4096,), dtype: int8\n",
            "Accumulateur dtype: int16\n"
          ]
        }
      ],
      "source": [
        "D = 4096\n",
        "n = 3\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "sentences = [\n",
        "    \"hyperdimensional computing is fun\",\n",
        "    \"vector symbolic architectures are powerful\",\n",
        "    \"encoding words into hyperspace\"\n",
        "]\n",
        "\n",
        "Lex = m4.M4_LexEN_new(seed=1, D=D)\n",
        "pi = rng.permutation(D).astype(np.int64)\n",
        "encoded = pipeline.encode_corpus_ENC(sentences, Lex, pi, D, n, seg_seed0=999)\n",
        "\n",
        "E_list = [entry[\"E_seq\"] for entry in encoded]\n",
        "H_list = [entry[\"H\"] for entry in encoded]\n",
        "\n",
        "print(f\"Nombre de segments encodés: {len(encoded)}\")\n",
        "print(f\"Signature shape: {H_list[0].shape}, dtype: {H_list[0].dtype}\")\n",
        "print(f\"Accumulateur dtype: {encoded[0]['S'].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Métriques de similarité et courbes de majorité\n",
        "\n",
        "Nous reproduisons les indicateurs `intra/inter` ainsi que les courbes d'erreur de majorité."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarité intra n-gram (moyenne): 0.0008\n",
            "Similarité inter n-gram |.|: 0.0117\n",
            "Similarité inter segments |.|: 0.0173\n",
            "Majority error curve @eta=0.0: [(4, 0.09375), (5, 0.0)]\n",
            "Repeated-vector curve @eta=0.05: [(4, 0.012), (5, 0.0)]\n"
          ]
        }
      ],
      "source": [
        "s_intra, s_inter = pipeline.intra_inter_ngram_sims(E_list, D)\n",
        "inter_seg = pipeline.inter_segment_similarity(H_list)\n",
        "\n",
        "print(f\"Similarité intra n-gram (moyenne): {s_intra:.4f}\")\n",
        "print(f\"Similarité inter n-gram |.|: {s_inter:.4f}\")\n",
        "print(f\"Similarité inter segments |.|: {inter_seg:.4f}\")\n",
        "\n",
        "maj_curves = pipeline.majority_error_curve(E_list, pi, D, eta_list=(0.0, 0.05))\n",
        "print(\"Majority error curve @eta=0.0:\", maj_curves[0.0][:3])\n",
        "\n",
        "maj_repeat = pipeline.majority_curve_repeated_vector(E_list, pi, D, eta_list=(0.0, 0.05), trials_per_m=500)\n",
        "print(\"Repeated-vector curve @eta=0.05:\", maj_repeat[0.05][:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encodage fin : comparaison strict vs unbiased\n",
        "\n",
        "`M8_ENC` permet de choisir entre majorité strict (`strict`) et majority sans biais (`unbiased`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#E (unbiased) = 5, #X = 5, #Xb = 5\n",
            "H_unbiased unique values: [-1, 1]\n",
            "H_strict unique values: [-1, 1]\n"
          ]
        }
      ],
      "source": [
        "tokens = \"time flies like an arrow\".split()\n",
        "\n",
        "E_uni, X_uni, Xb_uni, S_uni, H_uni = pipeline.M8_ENC(\n",
        "    tokens, pi, n=2, LexEN=Lex, D=D,\n",
        "    majority_mode=\"unbiased\", return_bound=True\n",
        ")\n",
        "E_strict, X_strict, S_strict, H_strict = pipeline.M8_ENC(\n",
        "    tokens, pi, n=2, LexEN=Lex, D=D,\n",
        "    majority_mode=\"strict\", return_bound=False\n",
        ")\n",
        "\n",
        "print(f\"#E (unbiased) = {len(E_uni)}, #X = {len(X_uni)}, #Xb = {len(Xb_uni)}\")\n",
        "print(f\"H_unbiased unique values: {sorted(set(H_uni.tolist()))}\")\n",
        "print(f\"H_strict unique values: {sorted(set(H_strict.tolist()))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71431dec",
      "metadata": {},
      "source": [
        "# MEM . Part 2 : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c8674da2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Iterable, Tuple\n",
        "import numpy as np\n",
        "\n",
        "HD = np.int8   # vecteurs HD en ±1 stockés en int8\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ENFRPair:\n",
        "    Z_en: np.ndarray  # shape=(D,), dtype=int8, valeurs {-1,+1}\n",
        "    Z_fr: np.ndarray  # shape=(D,), dtype=int8, valeurs {-1,+1}\n",
        "\n",
        "def check_pair(pair: ENFRPair) -> None:\n",
        "    \"\"\"Valide qu'une paire (Z_en, Z_fr) respecte le contrat : \n",
        "       même shape, dtype=int8, valeurs dans {-1,+1}.\"\"\"\n",
        "    z_en, z_fr = pair.Z_en, pair.Z_fr\n",
        "    if z_en.dtype != HD or z_fr.dtype != HD or z_en.shape != z_fr.shape:\n",
        "        raise ValueError(\"Shapes/Types incohérents : attendu (D,), dtype=int8 pour EN et FR.\")\n",
        "    # Vérification stricte des valeurs (optionnelle, coûteuse si gros corpus)\n",
        "    # if not (np.all((z_en == 1)|(z_en == -1)) and np.all((z_fr == 1)|(z_fr == -1))):\n",
        "    #     raise ValueError(\"Valeurs attendues : {-1,+1}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f2837018",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bind_tranche(X: np.ndarray, G: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Applique le binding de tranche :\n",
        "       - X et G : vecteurs ±1 en int8\n",
        "       - retourne X ⊗ G en int8\n",
        "       - garantit isométrie & involutivité\n",
        "    \"\"\"\n",
        "    if X.dtype != np.int8 or G.dtype != np.int8:\n",
        "        raise ValueError(\"X,G doivent être en int8 (±1).\")\n",
        "    if X.shape != G.shape:\n",
        "        raise ValueError(\"X et G doivent avoir la même shape.\")\n",
        "    # int16 transitoire pour éviter débordement intermédiaire\n",
        "    return (X.astype(np.int16) * G.astype(np.int16)).astype(np.int8, copy=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84346b08",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class MemComponents:\n",
        "    mem: MemBank\n",
        "    lsh: SignLSH\n",
        "    Gmem: np.ndarray\n",
        "    meta: dict\n",
        "\n",
        "def _lsh_bucket(lsh: SignLSH, z_mem: np.ndarray, B: int) -> int:\n",
        "    \"\"\"Bucketisation robuste vers [0..B-1].\n",
        "       Préfère lsh.bucket_unbiased(z,B) si disponible, sinon fallback modulo.\"\"\"\n",
        "    if hasattr(lsh, \"bucket_unbiased\"):\n",
        "        return int(lsh.bucket_unbiased(z_mem, B))\n",
        "    code = int(lsh.code(z_mem))\n",
        "    return code % int(B)\n",
        "\n",
        "def train_one_pass_MEM(components: MemComponents,\n",
        "                       pairs_en_fr: Iterable[Tuple[np.ndarray, np.ndarray]]) -> None:\n",
        "    \"\"\"Chaîne MM6 complète: bind→LSH→bucket→update (cf. MM6, MM5, MM3, MM4).\"\"\"\n",
        "    mem, lsh, Gmem = components.mem, components.lsh, components.Gmem\n",
        "    D = int(Gmem.shape[0])\n",
        "    if Gmem.dtype != np.int8:\n",
        "        raise ValueError(\"Gmem doit être en int8 (±1).\")\n",
        "    for Z_en, Z_fr in pairs_en_fr:\n",
        "        Z_en = Z_en.astype(np.int8, copy=False)\n",
        "        Z_fr = Z_fr.astype(np.int8, copy=False)\n",
        "        if Z_en.shape != (D,) or Z_fr.shape != (D,):\n",
        "            raise ValueError(\"Z_en, Z_fr doivent avoir shape=(D,).\")\n",
        "        Z_en_mem = to_mem_tranche(Z_en, Gmem)              # MM5\n",
        "        c = _lsh_bucket(lsh, Z_en_mem, mem.B)              # *** FIX: bucketisation ***\n",
        "        mem.add(c, Z_fr)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "142be1fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass(frozen=True)\n",
        "class SignLSH:\n",
        "    idx_bits: np.ndarray  # (k,) indices uniques [0..D-1], dtype=int64\n",
        "\n",
        "    @property\n",
        "    def k(self) -> int:\n",
        "        return int(self.idx_bits.shape[0])\n",
        "\n",
        "    @staticmethod\n",
        "    def with_k_bits(D: int, k: int, seed: Optional[int] = None) -> \"SignLSH\":\n",
        "        assert 1 <= k <= D\n",
        "        g = np.random.default_rng(seed)\n",
        "        bits = g.choice(D, size=int(k), replace=False)\n",
        "        return SignLSH(idx_bits=bits.astype(np.int64, copy=False))\n",
        "\n",
        "    def code(self, z_mem: np.ndarray) -> int:\n",
        "        z = z_mem if z_mem.dtype == np.int8 else z_mem.astype(np.int8, copy=False)\n",
        "        b = (z[self.idx_bits] > 0).astype(np.uint8, copy=False)\n",
        "        c = 0\n",
        "        for bit in b: c = (c << 1) | int(bit)\n",
        "        return int(c)  # c in [0, 2^k)\n",
        "\n",
        "    def bucket_mod(self, z_mem: np.ndarray, B: int) -> int:\n",
        "        \"\"\"Bucketisation simple: modulo (léger biais si 2^k % B != 0).\"\"\"\n",
        "        return self.code(z_mem) % int(B)\n",
        "\n",
        "    def bucket_unbiased(self, z_mem: np.ndarray, B: int) -> int:\n",
        "        \"\"\"Réduction quasi-sans biais: floor(code * B / 2^k).\"\"\"\n",
        "        code = self.code(z_mem)\n",
        "        return int((code * int(B)) >> self.k)\n",
        "\n",
        "def _mix32(x: int) -> int:\n",
        "    \"\"\"Mix 32-bit (xorshift-like) pour mieux répartir les codes avant modulo.\"\"\"\n",
        "    x ^= (x << 13) & 0xFFFFFFFF\n",
        "    x ^= (x >> 17)\n",
        "    x ^= (x << 5)  & 0xFFFFFFFF\n",
        "    return x & 0xFFFFFFFF\n",
        "\n",
        "def code_to_bucket(code: int, B: int) -> int:\n",
        "    \"\"\"Mappe un code entier vers un bucket [0..B-1] via mix léger + modulo.\"\"\"\n",
        "    if B <= 0:\n",
        "        raise ValueError(\"B doit être > 0\")\n",
        "    return _mix32(code) % int(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "94477ee7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bind_tranche_batch(X: np.ndarray, G: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Binding de tranche compatible batch.\n",
        "    \n",
        "    Args:\n",
        "        X : (D,) ou (n,D) int8 ±1\n",
        "        G : (D,) int8 ±1\n",
        "    Returns:\n",
        "        Y : même shape que X, en int8, tel que Y = X ⊗ G (broadcast sur l'axe n)\n",
        "    \n",
        "    Invariants:\n",
        "        - types contrôlés (int8)\n",
        "        - cast transitoire en int16 pour éviter overflow\n",
        "        - retour en int8, sans copies inutiles\n",
        "    \"\"\"\n",
        "    if G.dtype != np.int8:\n",
        "        raise ValueError(\"G doit être en int8 (±1).\")\n",
        "    if X.dtype != np.int8:\n",
        "        raise ValueError(\"X doit être en int8 (±1).\")\n",
        "    if G.ndim != 1:\n",
        "        raise ValueError(\"G doit avoir shape (D,), pas de dimension batch.\")\n",
        "    if X.ndim == 1:\n",
        "        if X.shape != G.shape:\n",
        "            raise ValueError(\"X et G doivent avoir la même shape (D,) en 1D.\")\n",
        "        return (X.astype(np.int16) * G.astype(np.int16)).astype(np.int8, copy=False)\n",
        "    elif X.ndim == 2:\n",
        "        n, D = X.shape\n",
        "        if G.shape != (D,):\n",
        "            raise ValueError(\"Pour X (n,D), G doit avoir shape (D,).\")\n",
        "        return (X.astype(np.int16) * G.astype(np.int16)[None, :]).astype(np.int8, copy=False)\n",
        "    else:\n",
        "        raise ValueError(\"X doit être (D,) ou (n,D).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d41b0fb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _rand_pm1(n: int, D: int, seed: int) -> np.ndarray:\n",
        "    \"\"\"Génère n vecteurs ±1 (int8) de dimension D, \n",
        "       reproductibles via un seed.\"\"\"\n",
        "    g = np.random.default_rng(seed)\n",
        "    B = g.integers(0, 2, size=(n, D), dtype=np.int8)\n",
        "    return (B << 1) - 1   # map {0,1} -> {-1,+1}\n",
        "\n",
        "def test_isometrie_involutivite(D=8192, trials=100, seed=0):\n",
        "    \"\"\"Vérifie que :\n",
        "       - le binding préserve les produits scalaires (isométrie)\n",
        "       - le binding répété rend l’original (involutivité)\n",
        "       Version compatible avec bind_tranche_batch (1D).\n",
        "    \"\"\"\n",
        "    g = np.random.default_rng(seed)\n",
        "    for t in range(trials):\n",
        "        X = _rand_pm1(1, D, seed+2*t)[0]   # (D,)\n",
        "        Y = _rand_pm1(1, D, seed+2*t+1)[0] # (D,)\n",
        "        G = _rand_pm1(1, D, seed+3*t)[0]   # (D,)\n",
        "\n",
        "        # produit scalaire de référence\n",
        "        dot0 = int((X.astype(np.int32) * Y.astype(np.int32)).sum())\n",
        "\n",
        "        # après binding (utilisation 1D de la version batch-safe)\n",
        "        Xg = bind_tranche_batch(X, G)      # (D,)\n",
        "        Yg = bind_tranche_batch(Y, G)      # (D,)\n",
        "        dot1 = int((Xg.astype(np.int32) * Yg.astype(np.int32)).sum())\n",
        "        assert dot0 == dot1, \"Isométrie violée\"\n",
        "\n",
        "        # involutivité : (X ⊗ G) ⊗ G == X\n",
        "        assert np.array_equal(bind_tranche_batch(Xg, G), X), \"Involutivité violée\"\n",
        "    return True\n",
        "\n",
        "\n",
        "def test_etancheite_inter_tranches(D=16384, n=4000, eps=0.05, seed=7):\n",
        "    \"\"\"Teste l’indépendance statistique de deux bindings \n",
        "       avec clés de tranche différentes (étanchéité), version batch.\n",
        "    \"\"\"\n",
        "    X  = _rand_pm1(n, D, seed)            # (n,D)\n",
        "    G  = _rand_pm1(1, D, seed+1)[0]       # (D,)\n",
        "    Gp = _rand_pm1(1, D, seed+2)[0]       # (D,)\n",
        "\n",
        "    # Binding batch-safe (vectorisé)\n",
        "    Xg  = bind_tranche_batch(X,  G)       # (n,D)\n",
        "    Xgp = bind_tranche_batch(X, Gp)       # (n,D)\n",
        "\n",
        "    # sim_i = <Xg_i, Xgp_i>/D\n",
        "    sims = ((Xg.astype(np.int32) * Xgp.astype(np.int32)).sum(axis=1) / D).astype(np.float64)\n",
        "    mean, tail = float(sims.mean()), float((np.abs(sims) > eps).mean())\n",
        "    bound = 2.0 * math.exp(- D * eps * eps / 2.0)\n",
        "\n",
        "    assert abs(mean) < 1e-2 + 1e-3, \"Centrage inter-tranches anormal\"\n",
        "    assert tail <= bound + 1e-6,    \"Queue empirique > borne de Hoeffding\"\n",
        "    return {\"mean\": mean, \"tail\": tail, \"bound\": bound}\n",
        "\n",
        "\n",
        "def test_indexer_post_binding(D=16384, B=1000, k=24, seed=11):\n",
        "    \"\"\"Vérifie que l’indexeur Sign-LSH appliqué après binding\n",
        "       garde un taux de collisions acceptable (<0.5%).\n",
        "    \"\"\"\n",
        "    slsh = SignLSH.with_k_bits(D, k, seed)    # indexeur aléatoire k-bits\n",
        "    Z  = _rand_pm1(B, D, seed+1)              # (B,D)\n",
        "    G  = _rand_pm1(1, D, seed+2)[0]           # (D,)\n",
        "\n",
        "    # Binding batch-safe pour tout le lot\n",
        "    Zg = bind_tranche_batch(Z, G)             # (B,D)\n",
        "\n",
        "    # Codes LSH puis estimation du taux de collisions\n",
        "    codes = np.array([slsh.code(zg) for zg in Zg], dtype=np.int64)\n",
        "    uniq = np.unique(codes).size\n",
        "    coll = 1.0 - uniq / B\n",
        "    assert coll <= 0.005 + 1e-6, f\"Collisions élevées: {coll:.3%}\"\n",
        "    return {\"collisions\": float(coll), \"uniq\": int(uniq)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4dd9816b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'collisions': 0.0, 'uniq': 1000}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_isometrie_involutivite()\n",
        "test_etancheite_inter_tranches()\n",
        "test_indexer_post_binding()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8df452",
      "metadata": {},
      "source": [
        "## MM3. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e6fb0123",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class MultiSignLSH:\n",
        "    \"\"\"T indexeurs signe-LSH indépendants; fusion XOR des codes k-bits.\"\"\"\n",
        "    tables: List[SignLSH]\n",
        "\n",
        "    @staticmethod\n",
        "    def build(D: int, k: int, T: int, seed: Optional[int] = None) -> \"MultiSignLSH\":\n",
        "        g = np.random.default_rng(seed)\n",
        "        # seed dérivés pour assurer indépendance\n",
        "        tables = [SignLSH.with_k_bits(D, k, int(g.integers(0, 2**31-1))) for _ in range(T)]\n",
        "        return MultiSignLSH(tables=tables)\n",
        "\n",
        "    def code(self, z_mem: np.ndarray) -> int:\n",
        "        c = 0\n",
        "        for t in self.tables:\n",
        "            c ^= t.code(z_mem)  # fusion XOR\n",
        "        return int(c)\n",
        "\n",
        "    def bucket(self, z_mem: np.ndarray, B: int) -> int:\n",
        "        return code_to_bucket(self.code(z_mem), B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d4ddfb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _rand_pm1(n: int, D: int, seed: int) -> np.ndarray:\n",
        "    g = np.random.default_rng(seed)\n",
        "    B = g.integers(0, 2, size=(n, D), dtype=np.int8)\n",
        "    return (B << 1) - 1  # {-1,+1}\n",
        "\n",
        "# --- (T1) Uniformité empirique des codes (sans bucket) ---\n",
        "def test_code_uniformity(D=16384, k=24, N=10000, seed=0):\n",
        "    slsh = SignLSH.with_k_bits(D, k, seed)\n",
        "    Z = _rand_pm1(N, D, seed+1)\n",
        "    codes = np.array([slsh.code(z) for z in Z], dtype=np.int64)\n",
        "    # Mesure rudimentaire : taux de remplissage vs 2^k (si N << 2^k, on s'attend à peu de collisions)\n",
        "    uniq = np.unique(codes).size\n",
        "    fill = uniq / min(N, 2**k)  # fraction de cases distinctes observées\n",
        "    return {\"uniq\": int(uniq), \"fill_fraction\": float(fill)}\n",
        "\n",
        "# --- (T2) Collisions vs k (bucket sur B) ---\n",
        "def test_bucket_collisions(D=16384, B=1000, k_list=(16,24,32), N=20000, seed=1):\n",
        "    g = np.random.default_rng(seed)\n",
        "    Z = _rand_pm1(N, D, seed+1)\n",
        "    results = {}\n",
        "    for k in k_list:\n",
        "        slsh = SignLSH.with_k_bits(D, k, int(g.integers(0, 2**31-1)))\n",
        "        buckets = np.array([code_to_bucket(slsh.code(z), B) for z in Z], dtype=np.int32)\n",
        "        # Collisions = 1 - (nb de buckets distincts / min(N,B))\n",
        "        uniq = np.unique(buckets).size\n",
        "        coll_frac = 1.0 - (uniq / min(N, B))\n",
        "        results[int(k)] = {\"uniq_buckets\": int(uniq), \"collision_fraction\": float(coll_frac)}\n",
        "    return results\n",
        "\n",
        "# --- (T3) Invariance sous binding (indexer après binding) ---\n",
        "def test_invariance_binding(D=16384, k=24, N=2000, seed=2):\n",
        "    slsh = SignLSH.with_k_bits(D, k, seed)\n",
        "    Z  = _rand_pm1(N, D, seed+1)\n",
        "    G  = _rand_pm1(1, D, seed+2)[0]\n",
        "    # codes sur Z⊗G et sur Z puis (option) mix (la distribution globale doit rester comparable)\n",
        "    from copy import deepcopy\n",
        "    Zg = (Z.astype(np.int16) * G.astype(np.int16)).astype(np.int8, copy=False)\n",
        "    codes_Z  = np.array([slsh.code(z)  for z in Z],  dtype=np.int64)\n",
        "    codes_Zg = np.array([slsh.code(zg) for zg in Zg], dtype=np.int64)\n",
        "    # On mesure le taux d'accord bit-à-bit (Hamming) moyen entre codes_Z et codes_Zg :\n",
        "    # (statistique indicative; attendre ~0.5 si indices choisis aléatoirement et G Rademacher)\n",
        "    # Ici on vérifie surtout l'absence de biais massif (mêmes distributions marginales).\n",
        "    agree = np.mean(codes_Z == codes_Zg)\n",
        "    return {\"match_fraction\": float(agree)}\n",
        "\n",
        "# --- (T4) Robustesse au bruit (flips coordonnés à taux q) ---\n",
        "def test_noise_stability(D=16384, k=24, q=0.01, N=2000, seed=3):\n",
        "    g  = np.random.default_rng(seed)\n",
        "    slsh = SignLSH.with_k_bits(D, k, seed+1)\n",
        "    Z  = _rand_pm1(N, D, seed+2)\n",
        "    # génère Z' en flipant chaque coordonnée avec prob q\n",
        "    flips = g.random((N, D)) < q\n",
        "    Zp = Z.copy()\n",
        "    Zp[flips] = -Zp[flips]\n",
        "    codes_Z  = np.array([slsh.code(z)  for z in Z],  dtype=np.int64)\n",
        "    codes_Zp = np.array([slsh.code(zp) for zp in Zp], dtype=np.int64)\n",
        "    # Taux d'accord des codes k-bits sous bruit\n",
        "    agree = np.mean(codes_Z == codes_Zp)\n",
        "    # Référence théorique ~ (1 - q)^k sous indépendance (approx.)\n",
        "    ref = (1.0 - q) ** k\n",
        "    return {\"empirical_agreement\": float(agree), \"theoretical_ref\": float(ref)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9909976d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'empirical_agreement': 0.772, 'theoretical_ref': 0.7856781408072188}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_code_uniformity()\n",
        "test_bucket_collisions()\n",
        "test_invariance_binding()\n",
        "test_noise_stability()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1108230e",
      "metadata": {},
      "source": [
        "## MM4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a775f4c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MemBank:\n",
        "    \"\"\"Banque associative HD (tranche G_MEM).\n",
        "    \n",
        "    - M : accumulateurs int32 (somme des payloads)\n",
        "    - H : prototypes seuillés en ±1 (majorité coordonnée)\n",
        "    - n : compte d'exemples par classe (m_c)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, B: int, D: int, thresh: bool = True) -> None:\n",
        "        assert B > 0 and D > 0\n",
        "        self.B, self.D, self.thresh = int(B), int(D), bool(thresh)\n",
        "        self.M = np.zeros((B, D), dtype=np.int32)\n",
        "        self.H = np.zeros((B, D), dtype=np.int8)\n",
        "        self.n = np.zeros((B,),   dtype=np.int32)\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_pm1(x: np.ndarray, D: int) -> None:\n",
        "        if x.dtype != np.int8 or x.shape != (D,):\n",
        "            raise ValueError(\"HD attendu: shape=(D,), dtype=int8\")\n",
        "        # Optionnel: vérifier que les valeurs sont bien ±1\n",
        "        # if not np.all((x == 1) | (x == -1)): raise ValueError(\"valeurs {-1,+1} attendues\")\n",
        "\n",
        "    def add(self, c: int, Z_fr: np.ndarray) -> None:\n",
        "        \"\"\"One-pass: M_c += Z_fr; n_c += 1; (option) H_c <- sign(M_c).\"\"\"\n",
        "        if not (0 <= c < self.B): raise IndexError(\"classe hors bornes\")\n",
        "        MemBank._check_pm1(Z_fr, self.D)\n",
        "        self.M[c, :] += Z_fr.astype(np.int32, copy=False)\n",
        "        self.n[c] += 1\n",
        "        if self.thresh:\n",
        "            self.H[c, :] = np.where(self.M[c, :] >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "\n",
        "    def seal(self, c: int) -> None:\n",
        "        \"\"\"Scellement explicite: H_c <- sign(M_c).\"\"\"\n",
        "        self.H[c, :] = np.where(self.M[c, :] >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "\n",
        "    # ----- Utilitaires pédagogiques (LLN & majorité) -----\n",
        "    def empirical_mean(self, c: int) -> np.ndarray:\n",
        "        \"\"\"Retourne m_c^{-1} M_c en float64 (nan si m_c=0).\"\"\"\n",
        "        if self.n[c] == 0:\n",
        "            return np.full((self.D,), np.nan, dtype=np.float64)\n",
        "        return (self.M[c, :].astype(np.float64) / float(self.n[c]))\n",
        "\n",
        "    def sign_error_rate(self, c: int, mu_true: np.ndarray) -> float:\n",
        "        \"\"\"Pour une vérité de référence mu_true (±biais par coordonnée),\n",
        "           retourne la fraction de bits où sign(M_c) ≠ sign(mu_true).\"\"\"\n",
        "        if mu_true.shape != (self.D,):\n",
        "            raise ValueError(\"mu_true: shape=(D,) requis\")\n",
        "        Hc = np.where(self.M[c, :] >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "        ref = np.where(mu_true >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "        return float(np.mean(Hc != ref))\n",
        "\n",
        "    def inf_norm_error(self, c: int, mu_true: np.ndarray) -> float:\n",
        "        \"\"\"Retourne || m_c^{-1} M_c - mu_true ||_∞ en float64.\"\"\"\n",
        "        return float(np.max(np.abs(self.empirical_mean(c) - mu_true)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "29a0e6de",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_fr_payloads(mu: np.ndarray, m: int, seed: int) -> np.ndarray:\n",
        "    \"\"\"Échantillonne m vecteurs Z_fr ∈ {-1,+1}^D avec E[Z_fr]=mu.\n",
        "    \n",
        "    Args:\n",
        "        mu   : cible moyenne (float64, shape=(D,), valeurs dans [-1,1])\n",
        "        m    : nombre d'échantillons\n",
        "        seed : graine pour reproductibilité\n",
        "    Returns:\n",
        "        Z    : array (m, D) en int8 ±1\n",
        "    \"\"\"\n",
        "    if mu.ndim != 1: raise ValueError(\"mu doit être 1D, shape=(D,)\")\n",
        "    D = mu.shape[0]\n",
        "    p = (1.0 + mu) / 2.0\n",
        "    p = np.clip(p, 0.0, 1.0)\n",
        "    g = np.random.default_rng(seed)\n",
        "    U = g.random(size=(m, D))\n",
        "    Z = np.where(U < p, 1, -1).astype(np.int8, copy=False)\n",
        "    return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7f2688c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_lln_coordinate(D=4096, m_list=(8,16,32,64), bias=0.2, seed=0):\n",
        "    \"\"\"Vérifie la décroissance ~ m^{-1/2} de ||m^{-1}M - mu||_∞.\"\"\"\n",
        "    g = np.random.default_rng(seed)\n",
        "    mu = np.full((D,), float(bias), dtype=np.float64)  # même biais sur toutes les coordonnées\n",
        "    mem = MemBank(B=1, D=D, thresh=True)\n",
        "    errs = []\n",
        "    for m in m_list:\n",
        "        Z = sample_fr_payloads(mu, m, seed + m)  # m échantillons biaisés\n",
        "        mem.M[0, :] = Z.astype(np.int32, copy=False).sum(axis=0)\n",
        "        mem.n[0] = m\n",
        "        mem.seal(0)\n",
        "        errs.append(mem.inf_norm_error(0, mu))\n",
        "    # Vérification monotone (indicative)\n",
        "    mono = all(errs[i] >= errs[i+1] - 1e-9 for i in range(len(errs)-1))\n",
        "    return {\"m_list\": list(m_list), \"inf_norm_errors\": [float(e) for e in errs], \"monotone\": bool(mono)}\n",
        "\n",
        "def test_majority_sign_error(D=4096, m=32, bias=0.2, seed=1):\n",
        "    \"\"\"Compare l'erreur de signe empirique à la borne exp(-m*bias^2/2).\"\"\"\n",
        "    mu = np.full((D,), float(bias), dtype=np.float64)\n",
        "    Z = sample_fr_payloads(mu, m, seed)\n",
        "    M = Z.astype(np.int32).sum(axis=0)\n",
        "    H = np.where(M >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    ref = np.where(mu >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    err_emp = float(np.mean(H != ref))\n",
        "    bound   = math.exp(- m * (bias**2) / 2.0)  # borne coordonnée\n",
        "    return {\"m\": int(m), \"bias\": float(bias), \"err_emp\": err_emp, \"hoeffding_bound\": bound}\n",
        "\n",
        "def test_tie_policy(D=4096, seed=2):\n",
        "    \"\"\"Teste la convention sign(0)=+1 et son effet sur des moyennes ~0.\"\"\"\n",
        "    mu = np.zeros((D,), dtype=np.float64)\n",
        "    Z  = sample_fr_payloads(mu, m=100, seed=seed)   # symétrique, E=0\n",
        "    M  = Z.astype(np.int32).sum(axis=0)\n",
        "    H  = np.where(M >= 0, 1, -1).astype(np.int8, copy=False)  # sign(0)=+1\n",
        "    frac_plus = float(np.mean(H == 1))\n",
        "    # Attendu: ≈ 0.5, léger excès dû à la convention sign(0)=+1.\n",
        "    return {\"frac_plus\": frac_plus}\n",
        "\n",
        "def test_seal_strategies_equivalence(D=4096, m=64, bias=0.1, seed=3):\n",
        "    \"\"\"Compare scellage en-ligne vs scellage final (équivalence attendue).\"\"\"\n",
        "    mu = np.full((D,), float(bias), dtype=np.float64)\n",
        "    Z  = sample_fr_payloads(mu, m, seed)\n",
        "    # 1) Scellage en ligne\n",
        "    mem1 = MemBank(B=1, D=D, thresh=True)\n",
        "    for s in range(m):\n",
        "        mem1.add(0, Z[s])\n",
        "    H1 = mem1.H[0].copy()\n",
        "\n",
        "    # 2) Scellage final\n",
        "    mem2 = MemBank(B=1, D=D, thresh=False)\n",
        "    for s in range(m):\n",
        "        mem2.add(0, Z[s])\n",
        "    mem2.seal(0)\n",
        "    H2 = mem2.H[0].copy()\n",
        "    return {\"equal\": bool(np.array_equal(H1, H2))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1e913e4c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'equal': True}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_lln_coordinate()\n",
        "test_majority_sign_error()\n",
        "test_tie_policy()\n",
        "test_seal_strategies_equivalence()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157c9876",
      "metadata": {},
      "source": [
        "## MM5 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c6c842e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_mem_tranche(X: np.ndarray, Gmem: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Projection en tranche MEM: X ⊗ Gmem (int8 sûr, involutif).\"\"\"\n",
        "    if X.dtype != np.int8 or Gmem.dtype != np.int8 or X.shape != Gmem.shape:\n",
        "        raise ValueError(\"X,Gmem: int8 ±1, même shape requis\")\n",
        "    return (X.astype(np.int16) * Gmem.astype(np.int16)).astype(np.int8, copy=False)\n",
        "\n",
        "# Unbinding = binding avec la même clé (involutif)\n",
        "from_mem_tranche = to_mem_tranche  # alias intentionnel\n",
        "\n",
        "def to_mem_tranche_batch(X: np.ndarray, Gmem: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Batch: X shape=(N,D), Gmem shape=(D,) -> retour (N,D).\"\"\"\n",
        "    if X.dtype != np.int8 or Gmem.dtype != np.int8: \n",
        "        raise ValueError(\"X, Gmem doivent être en int8\")\n",
        "    if X.ndim != 2 or X.shape[1] != Gmem.shape[0]:\n",
        "        raise ValueError(\"X: (N,D), Gmem: (D,)\")\n",
        "    return (X.astype(np.int16) * Gmem.astype(np.int16)).astype(np.int8, copy=False)\n",
        "\n",
        "def simhd(U: np.ndarray, V: np.ndarray) -> float:\n",
        "    \"\"\"Similarité HD normalisée: <U,V>/D en float64 (cohérent MM7).\"\"\"\n",
        "    if U.shape != V.shape or U.dtype != np.int8 or V.dtype != np.int8:\n",
        "        raise ValueError(\"U,V: même shape et dtype=int8 requis\")\n",
        "    D = U.shape[0]\n",
        "    return float((U.astype(np.int32) @ V.astype(np.int32)) / float(D))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5baba16a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _rand_pm1(n: int, D: int, seed: int) -> np.ndarray:\n",
        "    g = np.random.default_rng(seed)\n",
        "    B = g.integers(0, 2, size=(n, D), dtype=np.int8)\n",
        "    return (B << 1) - 1\n",
        "\n",
        "def test_isometry_involution(D=8192, trials=128, seed=0) -> bool:\n",
        "    for t in range(trials):\n",
        "        X = _rand_pm1(1, D, seed+3*t)[0]\n",
        "        Y = _rand_pm1(1, D, seed+3*t+1)[0]\n",
        "        G = _rand_pm1(1, D, seed+3*t+2)[0]\n",
        "        dot0 = int((X.astype(np.int32) * Y.astype(np.int32)).sum())\n",
        "        Xg, Yg = to_mem_tranche(X, G), to_mem_tranche(Y, G)\n",
        "        dot1 = int((Xg.astype(np.int32) * Yg.astype(np.int32)).sum())\n",
        "        assert dot0 == dot1, \"Isométrie violée\"\n",
        "        assert np.array_equal(to_mem_tranche(Xg, G), X), \"Involutivité violée\"\n",
        "    return True\n",
        "\n",
        "def test_seal_gram_isometry(D=4096, N=256, seed=1) -> float:\n",
        "    \"\"\"Isométrie niveau Gram: ||G - G'||_max ≤ 5e-3 (critère EM3).\"\"\"\n",
        "    X = _rand_pm1(N, D, seed)\n",
        "    G = _rand_pm1(1, D, seed+1)[0]\n",
        "    Xg = to_mem_tranche_batch(X, G)\n",
        "    # Gram normalisés\n",
        "    G0 = (X.astype(np.int32) @ X.T.astype(np.int32)) / float(D)\n",
        "    G1 = (Xg.astype(np.int32) @ Xg.T.astype(np.int32)) / float(D)\n",
        "    err_max = float(np.max(np.abs(G0 - G1)))\n",
        "    return err_max  # attendu ≤ 5e-3\n",
        "\n",
        "def test_inter_tranche_leakage(D=16384, n=4000, eps=0.05, seed=2):\n",
        "    \"\"\"Étanchéité: mean ~ 0, tail ≤ Hoeffding.\"\"\"\n",
        "    X  = _rand_pm1(n, D, seed)\n",
        "    G  = _rand_pm1(1, D, seed+1)[0]\n",
        "    Gp = _rand_pm1(1, D, seed+2)[0]\n",
        "    Xg  = to_mem_tranche_batch(X,  G)\n",
        "    Xgp = to_mem_tranche_batch(X, Gp)\n",
        "    sims = ((Xg.astype(np.int32) * Xgp.astype(np.int32)).sum(axis=1)/D).astype(np.float64)\n",
        "    mean = float(sims.mean())\n",
        "    tail = float((np.abs(sims) > eps).mean())\n",
        "    bound = 2.0 * math.exp(- D * eps * eps / 2.0)\n",
        "    return {\"mean\": mean, \"tail\": tail, \"bound\": bound}\n",
        "\n",
        "def test_permutation_equivariance(D=8192, trials=64, seed=3) -> bool:\n",
        "    g = np.random.default_rng(seed)\n",
        "    for t in range(trials):\n",
        "        X = _rand_pm1(1, D, seed+5*t)[0]\n",
        "        G = _rand_pm1(1, D, seed+5*t+1)[0]\n",
        "        # permutation aléatoire\n",
        "        pi = g.permutation(D).astype(np.int64)\n",
        "        Xp, Gp = X[pi], G[pi]\n",
        "        left  = to_mem_tranche(Xp, Gp)           # Π(X) ⊗ Π(G)\n",
        "        right = to_mem_tranche(X, G)[pi]         # Π(X ⊗ G)\n",
        "        assert np.array_equal(left, right), \"Équivariance à Π violée\"\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6e9908a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_isometry_involution()\n",
        "test_seal_gram_isometry()\n",
        "test_inter_tranche_leakage()\n",
        "test_permutation_equivariance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "98c24081",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sanity_mm5_mm3_mm7(D=8192, k=24, seed=7):\n",
        "    # clés/payloads jouets\n",
        "    Z_en = _rand_pm1(1, D, seed)[0]\n",
        "    R    = Z_en.copy()                   # requête identique (cas « propre »)\n",
        "    G    = _rand_pm1(1, D, seed+1)[0]\n",
        "\n",
        "    # indexation post-binding (MM3)\n",
        "    slsh = SignLSH.with_k_bits(D, k, seed+2)\n",
        "    code_en_mem = slsh.code(to_mem_tranche(Z_en, G))\n",
        "\n",
        "    # cohérence requête (MM7)\n",
        "    R_mem = to_mem_tranche(R, G)\n",
        "    code_req_mem = slsh.code(R_mem)\n",
        "\n",
        "    # Les codes sont égaux dans ce cas propre (mêmes bits aux mêmes positions)\n",
        "    return int(code_en_mem == code_req_mem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f5df01ce",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sanity_mm5_mm3_mm7()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3936461f",
      "metadata": {},
      "source": [
        "## MM6 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2e0ce80a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mem_train_one_pass(mem: MemBank,\n",
        "                       lsh: SignLSH,\n",
        "                       pairs_en_fr: Iterable[Tuple[np.ndarray, np.ndarray]],\n",
        "                       Gmem: np.ndarray) -> None:\n",
        "    D = int(Gmem.shape[0])\n",
        "    if Gmem.dtype != np.int8:\n",
        "        raise ValueError(\"Gmem doit être en int8 (±1).\")\n",
        "\n",
        "    for Z_en, Z_fr in pairs_en_fr:\n",
        "        Z_en = Z_en.astype(np.int8, copy=False)\n",
        "        Z_fr = Z_fr.astype(np.int8, copy=False)\n",
        "        if Z_en.shape != (D,) or Z_fr.shape != (D,):\n",
        "            raise ValueError(\"Z_en et Z_fr doivent avoir shape=(D,) identique à Gmem.\")\n",
        "\n",
        "        Z_en_mem = to_mem_tranche(Z_en, Gmem)      # binding (MM5)\n",
        "        # --- IMPORTANT: bucketisation du code k-bits vers [0..B-1]\n",
        "        c = lsh.bucket_unbiased(Z_en_mem, mem.B)   # ou .bucket_mod(...)\n",
        "\n",
        "        mem.add(c, Z_fr)\n",
        "\n",
        "def mem_train_one_pass_batch(mem: MemBank,\n",
        "                             lsh: SignLSH,\n",
        "                             Z_en_batch: np.ndarray,   # (N,D) int8 ±1\n",
        "                             Z_fr_batch: np.ndarray,   # (N,D) int8 ±1\n",
        "                             Gmem: np.ndarray) -> None:\n",
        "    if Z_en_batch.dtype != np.int8 or Z_fr_batch.dtype != np.int8:\n",
        "        raise ValueError(\"batches en int8 requis\")\n",
        "    if Z_en_batch.shape != Z_fr_batch.shape or Z_en_batch.shape[1] != Gmem.shape[0]:\n",
        "        raise ValueError(\"Shapes incohérents pour batch et Gmem\")\n",
        "    # 1) Binding vectorisé (N,D)\n",
        "    Z_en_mem = (Z_en_batch.astype(np.int16) * Gmem.astype(np.int16)).astype(np.int8, copy=False)\n",
        "    # 2) Indexation + 3) Updates\n",
        "    for i in range(Z_en_mem.shape[0]):\n",
        "        c = lsh.bucket_unbiased(Z_en_mem[i], mem.B)   # ou .bucket_mod(...)\n",
        "        mem.add(c, Z_fr_batch[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bcb5bc1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_order_invariance(D=4096, N=200, B=128, k=24, seed=0) -> bool:\n",
        "    \"\"\"Même banque finale si on permute l'ordre des paires.\"\"\"\n",
        "    G   = _rand_pm1(1, D, seed+1)[0]\n",
        "    lsh = SignLSH.with_k_bits(D, k, seed+2)\n",
        "    mem1 = MemBank(B=B, D=D, thresh=True)\n",
        "    mem2 = MemBank(B=B, D=D, thresh=True)\n",
        "    # génère N paires\n",
        "    Z_en = _rand_pm1(N, D, seed+3)\n",
        "    Z_fr = _rand_pm1(N, D, seed+4)\n",
        "    pairs = list(zip(Z_en, Z_fr))\n",
        "    # ordre 1\n",
        "    mem_train_one_pass(mem1, lsh, pairs, G)\n",
        "    # ordre 2 (mélangé)\n",
        "    rng = np.random.default_rng(seed+5)\n",
        "    pairs_perm = [pairs[i] for i in rng.permutation(N)]\n",
        "    mem_train_one_pass(mem2, lsh, pairs_perm, G)\n",
        "    # égalité stricte des banques\n",
        "    return bool(np.array_equal(mem1.M, mem2.M) and np.array_equal(mem1.H, mem2.H) and np.array_equal(mem1.n, mem2.n))\n",
        "\n",
        "def test_collision_accumulation(D=4096, B=8, k=8, seed=7) -> bool:\n",
        "    \"\"\"Force quelques collisions et vérifie l'addition sur la même ligne.\"\"\"\n",
        "    G   = _rand_pm1(1, D, seed+1)[0]\n",
        "    lsh = SignLSH.with_k_bits(D, k, seed+2)  # petit k -> plus de collisions\n",
        "    mem = MemBank(B=B, D=D, thresh=False)\n",
        "    # Deux clés différentes mais même bucket\n",
        "    z1, z2 = _rand_pm1(1, D, seed+3)[0], _rand_pm1(1, D, seed+4)[0]\n",
        "    c1, c2 = lsh.code(to_mem_tranche(z1, G)) % B, lsh.code(to_mem_tranche(z2, G)) % B\n",
        "    # on répète jusqu'à collision (sécurisé)\n",
        "    tries = 0\n",
        "    while c1 != c2 and tries < 1000:\n",
        "        z2 = _rand_pm1(1, D, seed+4+tries)[0]\n",
        "        c2 = lsh.code(to_mem_tranche(z2, G)) % B\n",
        "        tries += 1\n",
        "    # payloads FR\n",
        "    fr1, fr2 = _rand_pm1(1, D, seed+8)[0], _rand_pm1(1, D, seed+9)[0]\n",
        "    mem.add(c1, fr1); mem.add(c2, fr2)\n",
        "    # vérifie addition sur M[c1]\n",
        "    return bool(np.array_equal(mem.M[c1], fr1.astype(np.int32)+fr2.astype(np.int32)))\n",
        "\n",
        "def test_determinism(D=4096, N=300, B=128, k=24, seed=11) -> bool:\n",
        "    \"\"\"Même résultat à seeds identiques et données identiques.\"\"\"\n",
        "    G   = _rand_pm1(1, D, seed+1)[0]\n",
        "    lsh = SignLSH.with_k_bits(D, k, seed+2)\n",
        "    memA = MemBank(B=B, D=D, thresh=True)\n",
        "    memB = MemBank(B=B, D=D, thresh=True)\n",
        "    Z_en = _rand_pm1(N, D, seed+3)\n",
        "    Z_fr = _rand_pm1(N, D, seed+4)\n",
        "    pairs = list(zip(Z_en, Z_fr))\n",
        "    mem_train_one_pass(memA, lsh, pairs, G); mem_train_one_pass(memB, lsh, pairs, G)\n",
        "    return bool(np.array_equal(memA.M, memB.M) and np.array_equal(memA.H, memB.H))\n",
        "\n",
        "def test_complexity_trend(D_list=(2048,4096,8192), N=2000, B=64, k=24, seed=21) -> dict:\n",
        "    \"\"\"Vérifie que la latence par update croît ~ linéairement avec D (tendance).\"\"\"\n",
        "    res = {}\n",
        "    for D in D_list:\n",
        "        G   = _rand_pm1(1, D, seed+1)[0]\n",
        "        lsh = SignLSH.with_k_bits(D, k, seed+2)\n",
        "        mem = MemBank(B=B, D=D, thresh=True)\n",
        "        Z_en = _rand_pm1(N, D, seed+3)\n",
        "        Z_fr = _rand_pm1(N, D, seed+4)\n",
        "        t0 = time.perf_counter()\n",
        "        mem_train_one_pass(mem, lsh, list(zip(Z_en, Z_fr)), G)\n",
        "        ms = 1000.0 * (time.perf_counter() - t0) / N\n",
        "        res[int(D)] = float(ms)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cafec149",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{2048: 0.008137229538988322,\n",
              " 4096: 0.00944877095753327,\n",
              " 8192: 0.0133548749727197}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_order_invariance()\n",
        "test_collision_accumulation()\n",
        "test_determinism()\n",
        "test_complexity_trend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f356f1d",
      "metadata": {},
      "source": [
        "## MM7 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "67f6f148",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mem_scores(mem: MemBank,\n",
        "               R_mem: np.ndarray,\n",
        "               use_thresh: bool = True) -> np.ndarray:\n",
        "    \"\"\"Scores normalisés s_c = <R_mem, Proto_c>/D.\n",
        "\n",
        "    Args:\n",
        "        mem       : MemBank (M accumulateurs int32, H seuillés int8).\n",
        "        R_mem     : requête bindée (np.int8, ±1), shape=(D,)\n",
        "        use_thresh: True -> H (±1); False -> sign(M) (±1)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray (float64, shape=(B,)) : scores ∈ [-1,1]\n",
        "    \"\"\"\n",
        "    if R_mem.dtype != np.int8 or R_mem.shape != (mem.D,):\n",
        "        raise ValueError(\"R_mem doit être int8 ±1, shape=(D,)\")\n",
        "\n",
        "    T = mem.H if use_thresh else np.where(mem.M >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    dots = T.astype(np.int32, copy=False) @ R_mem.astype(np.int32, copy=False)\n",
        "    return (dots / float(mem.D)).astype(np.float64, copy=False)\n",
        "\n",
        "def mem_argmax(scores: np.ndarray) -> int:\n",
        "    return int(np.argmax(np.asarray(scores)))\n",
        "\n",
        "def mem_payload(mem: MemBank, c_star: int) -> np.ndarray:\n",
        "    out = mem.H[c_star, :].view()\n",
        "    out.setflags(write=False)  # lecture seule\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9eee083e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def topk_indices(scores: np.ndarray, k: int) -> np.ndarray:\n",
        "    \"\"\"Retourne les indices des k meilleurs scores (sans copier inutilement).\"\"\"\n",
        "    if k <= 0: return np.empty((0,), dtype=np.int64)\n",
        "    k = int(min(k, scores.shape[0]))\n",
        "    # argpartition (O(B)) puis tri local (O(k log k))\n",
        "    part = np.argpartition(scores, -k)[-k:]\n",
        "    return part[np.argsort(scores[part])[::-1]]\n",
        "\n",
        "def margin_top1(scores: np.ndarray) -> float:\n",
        "    \"\"\"Marge s_(1) - s_(2) (0 si B<2).\"\"\"\n",
        "    B = scores.shape[0]\n",
        "    if B < 2: return float(scores.max()) if B == 1 else 0.0\n",
        "    idx = topk_indices(scores, 2)\n",
        "    return float(scores[idx[0]] - scores[idx[1]])\n",
        "\n",
        "def argmax_tie_break(scores: np.ndarray, seed: int = 0) -> int:\n",
        "    \"\"\"Argmax avec tie-break déterministe par bruit infinitésimal.\"\"\"\n",
        "    g = np.random.default_rng(seed)\n",
        "    eps = g.uniform(low=0.0, high=1e-9, size=scores.shape).astype(scores.dtype)\n",
        "    return int(np.argmax(scores + eps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "34f4160a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mem_scores_chunked(mem: MemBank,\n",
        "                       R_mem: np.ndarray,\n",
        "                       chunk: int = 4096,\n",
        "                       use_thresh: bool = True) -> np.ndarray:\n",
        "    \"\"\"Calcule s_c par blocs (limite la RAM temporaire), retourne (B,).\"\"\"\n",
        "    if R_mem.dtype != np.int8 or R_mem.shape != (mem.D,):\n",
        "        raise ValueError(\"R_mem doit être int8 ±1, shape=(D,)\")\n",
        "\n",
        "    T = mem.H if use_thresh else np.where(mem.M >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    R32 = R_mem.astype(np.int32, copy=False)\n",
        "    B = mem.B\n",
        "    out = np.empty((B,), dtype=np.float64)\n",
        "    for start in range(0, B, chunk):\n",
        "        end = min(B, start + chunk)\n",
        "        dots = T[start:end, :].astype(np.int32, copy=False) @ R32\n",
        "        out[start:end] = dots / float(mem.D)\n",
        "    return out\n",
        "\n",
        "def mem_topk_stream(mem: MemBank, R_mem: np.ndarray, k: int = 5, use_thresh: bool = True):\n",
        "    \"\"\"Retourne (indices, scores) du top-k via un heap min (streaming).\"\"\"\n",
        "    if k <= 0: return np.empty((0,), dtype=np.int64), np.empty((0,), dtype=np.float64)\n",
        "    T = mem.H if use_thresh else np.where(mem.M >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "    R32 = R_mem.astype(np.int32, copy=False)\n",
        "    heap = []  # contient (score, idx), min-heap\n",
        "    for c in range(mem.B):\n",
        "        sc = float((T[c, :].astype(np.int32, copy=False) @ R32) / float(mem.D))\n",
        "        if len(heap) < k: heapq.heappush(heap, (sc, c))\n",
        "        elif sc > heap[0][0]: heapq.heapreplace(heap, (sc, c))\n",
        "    heap.sort(reverse=True)\n",
        "    scores = np.array([s for (s, _) in heap], dtype=np.float64)\n",
        "    idx    = np.array([i for (_, i) in heap], dtype=np.int64)\n",
        "    return idx, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "bb8f8929",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_order_preserved_H_vs_signM(B=16, D=4096, m=24, noise=0.01, seed=10):\n",
        "    \"\"\"Le top-1 est identique pour H et sign(M) quand la marge est suffisante.\"\"\"\n",
        "    g = np.random.default_rng(seed)\n",
        "    mem = MemBank(B=B, D=D, thresh=True)\n",
        "    G   = _rand_pm1(1, D, seed+1)[0]\n",
        "    FR  = _rand_pm1(B, D, seed+2)\n",
        "\n",
        "    # alimente la banque\n",
        "    for c in range(B):\n",
        "        for _ in range(m):\n",
        "            z = FR[c].copy()\n",
        "            flip = g.random(D) < noise\n",
        "            z[flip] = -z[flip]\n",
        "            mem.add(c, z)\n",
        "\n",
        "    # requête au hasard\n",
        "    c_true = int(g.integers(0, B))\n",
        "    R_mem  = to_mem_tranche(FR[c_true], G)\n",
        "    sH = mem_scores(mem, R_mem, use_thresh=True)\n",
        "    sM = mem_scores(mem, R_mem, use_thresh=False)\n",
        "\n",
        "    return {\"same_top1\": bool(mem_argmax(sH) == mem_argmax(sM)),\n",
        "            \"margin\": float(margin_top1(sH))}\n",
        "\n",
        "def test_off_tranche_noise(D=16384, B=512, eps=0.05, seed=20):\n",
        "    \"\"\"Scores contre prototypes d'une autre tranche : moyenne ~ 0, queue ≤ Hoeffding.\"\"\"\n",
        "    memA = MemBank(B=B, D=D, thresh=True)\n",
        "    memB = MemBank(B=B, D=D, thresh=True)\n",
        "    GA   = _rand_pm1(1, D, seed+1)[0]\n",
        "    GB   = _rand_pm1(1, D, seed+2)[0]\n",
        "    # prototypes jouets (symétriques)\n",
        "    ZA = _rand_pm1(B, D, seed+3)\n",
        "    ZB = _rand_pm1(B, D, seed+4)\n",
        "    for c in range(B):\n",
        "        memA.add(c, ZA[c]); memB.add(c, ZB[c])\n",
        "\n",
        "    # requête en tranche A, scorée contre prototypes de B\n",
        "    R  = _rand_pm1(1, D, seed+5)[0]\n",
        "    RA = to_mem_tranche(R, GA)\n",
        "    s  = mem_scores(memB, RA, use_thresh=True)  # mauvais G -> bruit\n",
        "    mean = float(s.mean())\n",
        "    tail = float((np.abs(s) > eps).mean())\n",
        "    bound = 2.0 * math.exp(- D * eps * eps / 2.0)\n",
        "    return {\"mean\": mean, \"tail\": tail, \"bound\": bound}\n",
        "\n",
        "def test_topk_chunk_vs_full(B=4096, D=2048, k=10, seed=30):\n",
        "    \"\"\"Comparaison chunké vs plein et top-k streaming vs tri complet.\"\"\"\n",
        "    mem  = MemBank(B=B, D=D, thresh=True)\n",
        "    G    = _rand_pm1(1, D, seed+1)[0]\n",
        "    FR   = _rand_pm1(B, D, seed+2)\n",
        "    for c in range(B): mem.add(c, FR[c])\n",
        "    Rm   = to_mem_tranche(_rand_pm1(1, D, seed+3)[0], G)\n",
        "\n",
        "    s_full = mem_scores(mem, Rm, use_thresh=True)\n",
        "    s_chunk = mem_scores_chunked(mem, Rm, chunk=512, use_thresh=True)\n",
        "    idx_full = topk_indices(s_full, k)\n",
        "    idx_stream, s_stream = mem_topk_stream(mem, Rm, k=k, use_thresh=True)\n",
        "\n",
        "    return {\"max_abs_diff\": float(np.max(np.abs(s_full - s_chunk))),\n",
        "            \"topk_equal\": bool(np.array_equal(np.sort(idx_full), np.sort(idx_stream)))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b0c14a11",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_abs_diff': 0.0, 'topk_equal': True}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_order_preserved_H_vs_signM()\n",
        "test_off_tranche_noise()\n",
        "test_topk_chunk_vs_full()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d84e014f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimate_margin(scores: np.ndarray) -> float:\n",
        "    \"\"\"Retourne la marge empirique (s_(1)-s_(2)) d'un vecteur de scores.\"\"\"\n",
        "    return margin_top1(scores)\n",
        "\n",
        "def required_dimension(B: int, delta: float, margin: float) -> int:\n",
        "    \"\"\"Calcule D minimal pour risque global ≲ delta, marge donnée.\"\"\"\n",
        "    if margin <= 0: return int(1e9)  # inatteignable sans marge\n",
        "    return int(math.ceil((2.0 / (margin * margin)) * math.log((2.0 * B) / max(delta, 1e-12))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742e6121",
      "metadata": {},
      "source": [
        "## MM8 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "228f030f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:69: SyntaxWarning: invalid escape sequence '\\h'\n",
            "<>:69: SyntaxWarning: invalid escape sequence '\\h'\n",
            "/var/folders/zg/w26r16bd5c11s4xr1f6lb4mh0000gn/T/ipykernel_58465/435444712.py:69: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  où 'proto'=(D,) int8 ±1 (ex: \\hat M_{c_{t-j}}),\n"
          ]
        }
      ],
      "source": [
        "def apply_perm_power(x: np.ndarray, pi: np.ndarray, power: int) -> np.ndarray:\n",
        "    \"\"\"Applique Π^power à un vecteur HD (±1).\n",
        "    \n",
        "    Args:\n",
        "        x     : (D,) int8 ±1\n",
        "        pi    : (D,) int64 permutation de base Π ( indices 0..D-1 )\n",
        "        power : entier (peut être négatif) ; Π^{-1} = permutation inverse\n",
        "\n",
        "    Returns:\n",
        "        y = Π^{power} x, vue sans copie si power==0\n",
        "    \"\"\"\n",
        "    if x.dtype != np.int8: raise ValueError(\"x doit être int8 ±1\")\n",
        "    if pi.dtype != np.int64 or pi.shape != (x.shape[0],):\n",
        "        raise ValueError(\"pi doit être une permutation int64 de shape (D,)\")\n",
        "\n",
        "    if power == 0:\n",
        "        return x  # évite copie\n",
        "    D = x.shape[0]\n",
        "    # exponentiation par répétition (power petit dans la pratique : ±W, ±γ_j)\n",
        "    if power > 0:\n",
        "        idx = pi.copy()\n",
        "        for _ in range(power - 1):\n",
        "            idx = idx[pi]  # composition de permutations\n",
        "        return x[idx]\n",
        "    else:\n",
        "        # power < 0 : utiliser l'inverse\n",
        "        inv = np.empty_like(pi)\n",
        "        inv[pi] = np.arange(D, dtype=np.int64)\n",
        "        p = -power\n",
        "        idx = inv.copy()\n",
        "        for _ in range(p - 1):\n",
        "            idx = idx[inv]\n",
        "        return x[idx]\n",
        "\n",
        "def superpose_signed(vectors: Sequence[np.ndarray],\n",
        "                     weights: Optional[Sequence[int]] = None) -> np.ndarray:\n",
        "    \"\"\"Somme pondérée en int16 des vecteurs ±1 puis seuillage en int8.\n",
        "    \n",
        "    Args:\n",
        "        vectors : liste de (D,) en int8 ±1\n",
        "        weights : liste d'entiers (mêmes longueur ou None -> tous =1)\n",
        "    Returns:\n",
        "        R : (D,) int8 ±1\n",
        "    \"\"\"\n",
        "    if len(vectors) == 0: raise ValueError(\"au moins un vecteur requis\")\n",
        "    D = vectors[0].shape[0]\n",
        "    acc = np.zeros((D,), dtype=np.int16)\n",
        "    if weights is None: weights = [1] * len(vectors)\n",
        "    for v, w in zip(vectors, weights):\n",
        "        if v.dtype != np.int8 or v.shape != (D,):\n",
        "            raise ValueError(\"vecteurs doivent être (D,) int8 ±1\")\n",
        "        acc += (w * v.astype(np.int16, copy=False)).astype(np.int16, copy=False)\n",
        "    return np.where(acc >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "\n",
        "def build_query_from_context(H_window: Sequence[np.ndarray],\n",
        "                             pi: np.ndarray,\n",
        "                             w_left: int, w_right: int,\n",
        "                             weights_ctx: Optional[Sequence[int]] = None,\n",
        "                             targets_hist: Optional[Sequence[Tuple[np.ndarray, int, int]]] = None\n",
        "                             ) -> np.ndarray:\n",
        "    \"\"\"Construit R à partir d'une fenêtre de spans ENC et d'un historique cible.\n",
        "\n",
        "    Args:\n",
        "        H_window    : liste [H^{(t0-w_left)}, ..., H^{(t0)}, ..., H^{(t0+w_right)}], chaque (D,) int8 ±1\n",
        "        pi          : permutation Π (D,) int64\n",
        "        w_left/right: taille de fenêtre à gauche/droite (cohérente avec H_window)\n",
        "        weights_ctx : poids entiers pour chaque offset u ∈ [-w_left..w_right]\n",
        "        targets_hist: liste optionnelle [(proto, beta, gamma), ...]\n",
        "                      où 'proto'=(D,) int8 ±1 (ex: \\hat M_{c_{t-j}}),\n",
        "                      'beta' poids entier, 'gamma' décalage positionnel (appliquer Π^{gamma})\n",
        "\n",
        "    Returns:\n",
        "        R : (D,) int8 ±1\n",
        "    \"\"\"\n",
        "    U = []\n",
        "    W = []\n",
        "    # (a) contexte source : aligne chaque H^{(t0+u)} par Π^{u}\n",
        "    if weights_ctx is None:\n",
        "        weights_ctx = [1] * (w_left + w_right + 1)\n",
        "    assert len(H_window) == (w_left + w_right + 1)\n",
        "    for u, H in zip(range(-w_left, w_right+1), H_window):\n",
        "        U.append(apply_perm_power(H, pi, power=u))\n",
        "        W.append(int(weights_ctx[u + w_left]))\n",
        "\n",
        "    # (b) historique cible : prototypes précédents, re-positionnés\n",
        "    if targets_hist is not None:\n",
        "        for proto, beta, gamma in targets_hist:\n",
        "            U.append(apply_perm_power(proto, pi, power=gamma))\n",
        "            W.append(int(beta))\n",
        "\n",
        "    # (c) superposition + seuillage\n",
        "    R = superpose_signed(U, W)\n",
        "    return R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a636f7d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_query_mem(R: np.ndarray, Gmem: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"R_mem = R ⊗ G_MEM (int8, isométrique, involutif).\"\"\"\n",
        "    return to_mem_tranche(R, Gmem)\n",
        "\n",
        "def infer_top1(mem: MemBank, R: np.ndarray, Gmem: np.ndarray, use_thresh: bool = True) -> Tuple[int, float]:\n",
        "    \"\"\"Chaîne complète: bind → scores → argmax.\"\"\"\n",
        "    R_mem = build_query_mem(R, Gmem)\n",
        "    s = mem_scores(mem, R_mem, use_thresh=use_thresh)\n",
        "    c_star = mem_argmax(s)\n",
        "    return c_star, float(s[c_star])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fa26ec6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_build_query_shapes_types(D: int = 4096, seed: int = 0) -> bool:\n",
        "    pi   = np.random.default_rng(seed).permutation(D).astype(np.int64)\n",
        "    H0   = _rand_pm1(1, D, seed+1)[0]\n",
        "    R    = build_query_from_context([H0], pi, 0, 0)\n",
        "    assert R.dtype == np.int8 and R.shape == (D,)\n",
        "    return True\n",
        "\n",
        "def test_query_isometry_involution(D: int = 8192, seed: int = 1) -> bool:\n",
        "    pi   = np.random.default_rng(seed).permutation(D).astype(np.int64)\n",
        "    H0   = _rand_pm1(1, D, seed+1)[0]\n",
        "    R    = build_query_from_context([H0], pi, 0, 0)\n",
        "    G    = _rand_pm1(1, D, seed+2)[0]\n",
        "    Rm   = build_query_mem(R, G)\n",
        "    # isométrie: <Rm, X> == <R, X⊗G>\n",
        "    X    = _rand_pm1(1, D, seed+3)[0]\n",
        "    dot1 = int((Rm.astype(np.int32) * X.astype(np.int32)).sum())\n",
        "    dot2 = int((R.astype(np.int32)  * to_mem_tranche(X, G).astype(np.int32)).sum())\n",
        "    assert dot1 == dot2\n",
        "    # involutif\n",
        "    assert np.array_equal(to_mem_tranche(Rm, G), R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "7e4103f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_build_query_shapes_types()\n",
        "test_query_isometry_involution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ad846bb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def similarity_vs_shift(D: int = 8192, Wl: int = 2, Wr: int = 2, seed: int = 2, deltas=range(-6,7)):\n",
        "    \"\"\"Construit R d'une fenêtre et mesure simhd(R, Π^Δ R).\"\"\"\n",
        "    g  = np.random.default_rng(seed)\n",
        "    pi = g.permutation(D).astype(np.int64)\n",
        "    Hs = [_rand_pm1(1, D, seed+10+u)[0] for u in range(-Wl, Wr+1)]\n",
        "    R  = build_query_from_context(Hs, pi, Wl, Wr)  # w=1 par défaut\n",
        "    sims = {}\n",
        "    for Δ in deltas:\n",
        "        Rp = apply_perm_power(R, pi, Δ)\n",
        "        # simhd = <R, Π^Δ R> / D\n",
        "        s = float((R.astype(np.int32) @ Rp.astype(np.int32)) / float(D))\n",
        "        sims[int(Δ)] = s\n",
        "    return sims  # décroissance attendue quand |Δ| ↑\n",
        "\n",
        "def margin_drop_with_shift(B: int = 64, D: int = 8192, Wl: int = 1, Wr: int = 1, seed: int = 3, deltas=range(0,6)):\n",
        "    \"\"\"Impact du décalage sur la marge MAP en scorant contre une banque jouet.\"\"\"\n",
        "    g   = np.random.default_rng(seed)\n",
        "    pi  = g.permutation(D).astype(np.int64)\n",
        "    mem = MemBank(B=B, D=D, thresh=True)\n",
        "    G   = _rand_pm1(1, D, seed+1)[0]\n",
        "    # Prototypes FR (un seul échantillon pour illustrer)\n",
        "    FR  = _rand_pm1(B, D, seed+2)\n",
        "    for c in range(B): mem.add(c, FR[c])\n",
        "\n",
        "    # Construit une fenêtre rangée autour de t0 pour la classe vraie\n",
        "    Hs_true = [_rand_pm1(1, D, seed+10+u)[0] for u in range(-Wl, Wr+1)]\n",
        "    R0 = build_query_from_context(Hs_true, pi, Wl, Wr)\n",
        "    # c_true tirée au hasard\n",
        "    c_true = int(g.integers(0, B))\n",
        "    # Pour rendre R corrélé à FR[c_true], on injecte un mélange (+) biaisé\n",
        "    R_mix = superpose_signed([R0, FR[c_true]], weights=[2, 1])\n",
        "\n",
        "    margins = {}\n",
        "    for Δ in deltas:\n",
        "        # simule un décalage de la fenêtre non compensé\n",
        "        R_shift = apply_perm_power(R_mix, pi, Δ)\n",
        "        c_star, s_star = infer_top1(mem, R_shift, G, use_thresh=True)\n",
        "        s_all = mem_scores(mem, build_query_mem(R_shift, G), use_thresh=True)\n",
        "        margins[int(Δ)] = {\"c_star\": int(c_star), \"margin\": float(margin_top1(s_all))}\n",
        "    return margins  # marge ↓ quand Δ ↑ (tendance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "af0a164c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def window_effect_study(D: int = 8192, seed: int = 4, deltas=range(0,6)):\n",
        "    g  = np.random.default_rng(seed)\n",
        "    pi = g.permutation(D).astype(np.int64)\n",
        "    # deux fenêtres: étroite (1,1) et large (3,3)\n",
        "    configs = [(\"narrow\",(1,1), [1,1,1]), (\"wide\",(3,3), [1,1,1,1,1,1,1])]\n",
        "    curves = {}\n",
        "    for name,(Wl,Wr),weights in configs:\n",
        "        Hs = [_rand_pm1(1, D, seed+10+u)[0] for u in range(-Wl, Wr+1)]\n",
        "        R  = build_query_from_context(Hs, pi, Wl, Wr, weights_ctx=weights)\n",
        "        sims = []\n",
        "        for Δ in deltas:\n",
        "            Rp = apply_perm_power(R, pi, Δ)\n",
        "            s  = float((R.astype(np.int32) @ Rp.astype(np.int32)) / float(D))\n",
        "            sims.append(s)\n",
        "        curves[name] = sims\n",
        "    return curves  # la fenêtre large décroit plus lentement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "87eb8ea9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'narrow': [1.0,\n",
              "  0.025390625,\n",
              "  -0.0068359375,\n",
              "  0.0107421875,\n",
              "  0.00439453125,\n",
              "  -0.021484375],\n",
              " 'wide': [1.0,\n",
              "  0.00634765625,\n",
              "  0.0146484375,\n",
              "  0.0029296875,\n",
              "  -0.009765625,\n",
              "  -0.00927734375]}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_effect_study()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1164ed9e",
      "metadata": {},
      "source": [
        "## MM9 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f4e8a47a",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass(frozen=True)\n",
        "class MemConfig:\n",
        "    B: int           # nombre de buckets/classes mémoire\n",
        "    D: int           # dimension HD\n",
        "    k: int           # nombre de bits LSH (MM3)\n",
        "    seed_lsh: int    # seed pour LSH\n",
        "    seed_gmem: int   # seed pour la tranche G_MEM\n",
        "    thresh: bool = True  # seuillage en-ligne (MM4)\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class MemComponents:\n",
        "    mem: MemBank\n",
        "    lsh: SignLSH\n",
        "    Gmem: np.ndarray  # (D,) int8 ±1\n",
        "    meta: Dict[str, Any]\n",
        "\n",
        "def make_mem_pipeline(cfg: MemConfig) -> MemComponents:\n",
        "    \"\"\"Construit les composants MEM : banque, LSH, G_MEM ; journalise les seeds.\"\"\"\n",
        "    mem  = MemBank(B=cfg.B, D=cfg.D, thresh=cfg.thresh)\n",
        "    lsh  = SignLSH.with_k_bits(cfg.D, cfg.k, seed=cfg.seed_lsh)\n",
        "    # Gmem : Rademacher en ±1\n",
        "    g    = np.random.default_rng(cfg.seed_gmem)\n",
        "    Gmem = ((g.integers(0, 2, size=(cfg.D,), dtype=np.int8) << 1) - 1).astype(np.int8, copy=False)\n",
        "    meta = {\"B\": cfg.B, \"D\": cfg.D, \"k\": cfg.k, \"seed_lsh\": cfg.seed_lsh, \"seed_gmem\": cfg.seed_gmem,\n",
        "            \"thresh\": cfg.thresh, \"numpy_version\": np.__version__}\n",
        "    return MemComponents(mem=mem, lsh=lsh, Gmem=Gmem, meta=meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e7e139ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_pass_MEM(components: MemComponents,\n",
        "                       pairs_en_fr: Iterable[Tuple[np.ndarray, np.ndarray]]) -> None:\n",
        "    \"\"\"Chaîne MM6 complète: bind→LSH→update (cf. MM6, MM5, MM3, MM4).\"\"\"\n",
        "    mem, lsh, Gmem = components.mem, components.lsh, components.Gmem\n",
        "    for Z_en, Z_fr in pairs_en_fr:\n",
        "        Z_en = Z_en.astype(np.int8, copy=False)\n",
        "        Z_fr = Z_fr.astype(np.int8, copy=False)\n",
        "        Z_en_mem = to_mem_tranche(Z_en, Gmem)  # MM5\n",
        "        c = lsh.code(Z_en_mem)                 # MM3\n",
        "        mem.add(c, Z_fr)                       # MM4\n",
        "\n",
        "def infer_map_top1(components: MemComponents,\n",
        "                   R: np.ndarray,\n",
        "                   use_thresh: bool = True) -> Tuple[int, float]:\n",
        "    \"\"\"Chaîne MM7 complète: bind requête → scores → argmax (MAP).\"\"\"\n",
        "    R_mem = build_query_mem(R.astype(np.int8, copy=False), components.Gmem)  # MM5\n",
        "    scores = mem_scores(components.mem, R_mem, use_thresh=use_thresh)        # MM7\n",
        "    c_star = mem_argmax(scores)\n",
        "    return c_star, float(scores[c_star])\n",
        "\n",
        "def infer_map_topk(components: MemComponents,\n",
        "                   R: np.ndarray, k: int = 5,\n",
        "                   use_thresh: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Top-k via utilitaires MM7 (chunking/streaming possible).\"\"\"\n",
        "    R_mem = build_query_mem(R.astype(np.int8, copy=False), components.Gmem)\n",
        "    scores = mem_scores(components.mem, R_mem, use_thresh=use_thresh)\n",
        "    idx = topk_indices(scores, k)\n",
        "    return idx, scores[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e72a6abf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_aligned_pairs(B: int, D: int, m_per_class: int,\n",
        "                       noise_fr: float, noise_en: float,\n",
        "                       seed_proto: int, seed_stream: int) -> Dict[str, Any]:\n",
        "    \"\"\"Crée B prototypes FR et génère m_per_class paires EN/FR corrélées par classe.\n",
        "    \n",
        "    EN = Π P_c avec flips (noise_en).\n",
        "    FR = P_c avec flips (noise_fr).\n",
        "    \"\"\"\n",
        "    g  = np.random.default_rng(seed_proto)\n",
        "    pi = g.permutation(D).astype(np.int64)          # Π (MM1)\n",
        "    P  = _rand_pm1(B, D, seed_proto+1)              # prototypes FR\n",
        "    # génère paires\n",
        "    pairs = []\n",
        "    g2 = np.random.default_rng(seed_stream)\n",
        "    for c in range(B):\n",
        "        for _ in range(m_per_class):\n",
        "            z_fr = P[c].copy()\n",
        "            flip_fr = g2.random(D) < noise_fr\n",
        "            z_fr[flip_fr] = -z_fr[flip_fr]\n",
        "            # clé EN corrélée : ΠP_c puis flips\n",
        "            z_en = P[c][pi].copy()\n",
        "            flip_en = g2.random(D) < noise_en\n",
        "            z_en[flip_en] = -z_en[flip_en]\n",
        "            pairs.append((z_en.astype(np.int8, copy=False),\n",
        "                          z_fr.astype(np.int8, copy=False)))\n",
        "    # requêtes propres (une par classe)\n",
        "    R_clean = P.copy()  # requêtes « idéales » côté FR (compatibles avec MM7)\n",
        "    return {\"pairs\": pairs, \"P\": P, \"pi\": pi, \"R_clean\": R_clean}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "fdcfae27",
      "metadata": {},
      "outputs": [],
      "source": [
        "def accept_leakage(D: int = 16384, n: int = 4000, eps: float = 0.05, seed: int = 7) -> dict:\n",
        "    \"\"\"Étanchéité inter-tranches (MM5) : moyenne≈0, queue ≤ Hoeffding (version batch).\"\"\"\n",
        "    X  = _rand_pm1(n, D, seed)           # (n,D) int8 ±1\n",
        "    G  = _rand_pm1(1, D, seed+1)[0]      # (D,)  int8 ±1\n",
        "    Gp = _rand_pm1(1, D, seed+2)[0]      # (D,)  int8 ±1\n",
        "\n",
        "    # --- Correctif: binding batch-safe ---\n",
        "    Xg  = bind_tranche_batch(X,  G)      # (n,D) int8\n",
        "    Xgp = bind_tranche_batch(X, Gp)      # (n,D) int8\n",
        "\n",
        "    # Similarités normalisées sim_i = <(X⊗G)_i, (X⊗G')_i>/D\n",
        "    sims = ((Xg.astype(np.int32) * Xgp.astype(np.int32)).sum(axis=1) / D).astype(np.float64)\n",
        "    mean = float(sims.mean())\n",
        "    tail = float((np.abs(sims) > eps).mean())\n",
        "    bound = 2.0 * math.exp(- D * eps * eps / 2.0)\n",
        "\n",
        "    ok = (abs(mean) <= 1e-2 and tail <= bound + 1e-6)\n",
        "    return {\"mean\": mean, \"tail\": tail, \"bound\": bound, \"ok\": bool(ok)}\n",
        "\n",
        "def accept_collisions(D: int = 16384, B: int = 1000, k: int = 24, seed: int = 13) -> dict:\n",
        "    \"\"\"Taux de collisions LSH (MM3).\"\"\"\n",
        "    lsh = SignLSH.with_k_bits(D, k, seed)\n",
        "    X = _rand_pm1(B, D, seed+1)\n",
        "    codes = np.array([lsh.code(x) for x in X], dtype=np.int64)\n",
        "    uniq = np.unique(codes).size\n",
        "    coll = 1.0 - uniq / B\n",
        "    return {\"collisions\": float(coll), \"uniq\": int(uniq), \"ok\": (coll <= 0.005 + 1e-6)}\n",
        "\n",
        "def accept_train_infer_precision(cfg: MemConfig,\n",
        "                                 m_per_class: int = 32,\n",
        "                                 noise_fr: float = 0.01,\n",
        "                                 noise_en: float = 0.01,\n",
        "                                 seed_proto: int = 100,\n",
        "                                 seed_stream: int = 101,\n",
        "                                 seed_infer: int = 102) -> dict:\n",
        "    \"\"\"Entraîne puis évalue précision@1 sur requêtes propres (une par classe).\"\"\"\n",
        "    comp = make_mem_pipeline(cfg)\n",
        "    data = make_aligned_pairs(cfg.B, cfg.D, m_per_class, noise_fr, noise_en, seed_proto, seed_stream)\n",
        "    # train\n",
        "    t0 = time.perf_counter()\n",
        "    train_one_pass_MEM(comp, data[\"pairs\"])\n",
        "    train_ms = 1000.0 * (time.perf_counter() - t0)\n",
        "\n",
        "    # inference (B requêtes propres)\n",
        "    correct = 0\n",
        "    scores_all = []\n",
        "    for c in range(cfg.B):\n",
        "        R = data[\"R_clean\"][c]\n",
        "        c_star, s_star = infer_map_top1(comp, R, use_thresh=True)\n",
        "        correct += int(c_star == c)\n",
        "        scores_all.append(s_star)\n",
        "    prec1 = correct / float(cfg.B)\n",
        "    margin_est = float(np.sort(scores_all)[-1] - np.sort(scores_all)[-2]) if cfg.B >= 2 else float(scores_all[0])\n",
        "\n",
        "    return {\"prec_at_1\": float(prec1),\n",
        "            \"avg_score\": float(np.mean(scores_all)),\n",
        "            \"train_ms_total\": float(train_ms),\n",
        "            \"ok\": (prec1 >= 0.995)}  # CA sur requêtes propres\n",
        "\n",
        "def accept_determinism(cfg: MemConfig,\n",
        "                       m_per_class: int = 8,\n",
        "                       noise_fr: float = 0.01,\n",
        "                       noise_en: float = 0.01,\n",
        "                       seed_proto: int = 200,\n",
        "                       seed_stream: int = 201) -> dict:\n",
        "    \"\"\"Deux runs identiques (mêmes seeds) -> mêmes M/H.\"\"\"\n",
        "    compA = make_mem_pipeline(cfg)\n",
        "    compB = make_mem_pipeline(cfg)\n",
        "    dataA = make_aligned_pairs(cfg.B, cfg.D, m_per_class, noise_fr, noise_en, seed_proto, seed_stream)\n",
        "    dataB = make_aligned_pairs(cfg.B, cfg.D, m_per_class, noise_fr, noise_en, seed_proto, seed_stream)\n",
        "    train_one_pass_MEM(compA, dataA[\"pairs\"])\n",
        "    train_one_pass_MEM(compB, dataB[\"pairs\"])\n",
        "    same = (np.array_equal(compA.mem.M, compB.mem.M) and\n",
        "            np.array_equal(compA.mem.H, compB.mem.H) and\n",
        "            np.array_equal(compA.mem.n, compB.mem.n))\n",
        "    return {\"deterministic\": bool(same), \"ok\": bool(same)}\n",
        "\n",
        "def accept_complexity_trend(B: int = 128, D_list=(2048, 4096, 8192), k: int = 24,\n",
        "                            m_per_class: int = 8, seed: int = 300) -> dict:\n",
        "    \"\"\"Latence ∝ D (tendance).\"\"\"\n",
        "    out = {}\n",
        "    for D in D_list:\n",
        "        cfg = MemConfig(B=B, D=D, k=k, seed_lsh=seed+1, seed_gmem=seed+2)\n",
        "        comp = make_mem_pipeline(cfg)\n",
        "        data = make_aligned_pairs(B, D, m_per_class, 0.01, 0.01, seed+3, seed+4)\n",
        "        t0 = time.perf_counter()\n",
        "        train_one_pass_MEM(comp, data[\"pairs\"])\n",
        "        ms_per_upd = 1000.0 * (time.perf_counter() - t0) / (B * m_per_class)\n",
        "        out[int(D)] = float(ms_per_upd)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c4200825",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sanity_payload_readonly_and_isometry(cfg: MemConfig, seed: int = 400) -> dict:\n",
        "    comp = make_mem_pipeline(cfg)\n",
        "    # banque jouet : H = FR\n",
        "    FR = _rand_pm1(cfg.B, cfg.D, seed+1)\n",
        "    for c in range(cfg.B): comp.mem.add(c, FR[c])\n",
        "    # requête\n",
        "    R   = _rand_pm1(1, cfg.D, seed+2)[0]\n",
        "    Rm  = build_query_mem(R, comp.Gmem)\n",
        "    s1  = mem_scores(comp.mem, Rm, use_thresh=True)\n",
        "    # isométrie: <Rm, H> == <R, H⊗G>\n",
        "    H_bind = (comp.mem.H.astype(np.int16) * comp.Gmem.astype(np.int16)).astype(np.int8, copy=False)\n",
        "    s2  = (H_bind.astype(np.int32) @ R.astype(np.int32)) / float(cfg.D)\n",
        "    iso_ok = bool(np.allclose(s1, s2.astype(np.float64), atol=0.0))\n",
        "    # payload readonly\n",
        "    p    = mem_payload(comp.mem, int(np.argmax(s1)))\n",
        "    ro_ok = False\n",
        "    try:\n",
        "        p[0] = 0\n",
        "    except ValueError:\n",
        "        ro_ok = True\n",
        "    return {\"isometry_ok\": iso_ok, \"readonly_ok\": ro_ok, \"ok\": (iso_ok and ro_ok)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "33fdc243",
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "classe hors bornes",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m accept_leakage()\n\u001b[32m      2\u001b[39m accept_collisions()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43maccept_complexity_trend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36maccept_complexity_trend\u001b[39m\u001b[34m(B, D_list, k, m_per_class, seed)\u001b[39m\n\u001b[32m     85\u001b[39m data = make_aligned_pairs(B, D, m_per_class, \u001b[32m0.01\u001b[39m, \u001b[32m0.01\u001b[39m, seed+\u001b[32m3\u001b[39m, seed+\u001b[32m4\u001b[39m)\n\u001b[32m     86\u001b[39m t0 = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43mtrain_one_pass_MEM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpairs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m ms_per_upd = \u001b[32m1000.0\u001b[39m * (time.perf_counter() - t0) / (B * m_per_class)\n\u001b[32m     89\u001b[39m out[\u001b[38;5;28mint\u001b[39m(D)] = \u001b[38;5;28mfloat\u001b[39m(ms_per_upd)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_one_pass_MEM\u001b[39m\u001b[34m(components, pairs_en_fr)\u001b[39m\n\u001b[32m      8\u001b[39m Z_en_mem = to_mem_tranche(Z_en, Gmem)  \u001b[38;5;66;03m# MM5\u001b[39;00m\n\u001b[32m      9\u001b[39m c = lsh.code(Z_en_mem)                 \u001b[38;5;66;03m# MM3\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmem\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_fr\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mMemBank.add\u001b[39m\u001b[34m(self, c, Z_fr)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, c: \u001b[38;5;28mint\u001b[39m, Z_fr: np.ndarray) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"One-pass: M_c += Z_fr; n_c += 1; (option) H_c <- sign(M_c).\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m0\u001b[39m <= c < \u001b[38;5;28mself\u001b[39m.B): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mclasse hors bornes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m     MemBank._check_pm1(Z_fr, \u001b[38;5;28mself\u001b[39m.D)\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mself\u001b[39m.M[c, :] += Z_fr.astype(np.int32, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[31mIndexError\u001b[39m: classe hors bornes"
          ]
        }
      ],
      "source": [
        "accept_leakage()\n",
        "accept_collisions()\n",
        "accept_complexity_trend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563f8f20",
      "metadata": {},
      "source": [
        "## MM10 . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ff5281",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_types_shapes(mem: MemBank) -> Dict[str, Any]:\n",
        "    ok = (mem.M.dtype == np.int32 and mem.H.dtype == np.int8 and mem.n.dtype == np.int32)\n",
        "    return {\"M_dtype\": str(mem.M.dtype), \"H_dtype\": str(mem.H.dtype),\n",
        "            \"n_dtype\": str(mem.n.dtype), \"ok\": bool(ok)}\n",
        "\n",
        "def validate_tranche_isometry(G: np.ndarray, trials: int = 64, D: int = None, seed: int = 0) -> Dict[str, Any]:\n",
        "    \"\"\"Vérifie isométrie & involutivité (échantillonnage).\"\"\"\n",
        "    if D is None: D = G.shape[0]\n",
        "    g = np.random.default_rng(seed)\n",
        "    ok_iso = True; ok_inv = True\n",
        "    for t in range(trials):\n",
        "        X = ((g.integers(0,2,size=D,dtype=np.int8)<<1)-1)\n",
        "        Y = ((g.integers(0,2,size=D,dtype=np.int8)<<1)-1)\n",
        "        Xg, Yg = to_mem_tranche(X, G), to_mem_tranche(Y, G)\n",
        "        dot0 = int((X.astype(np.int32)*Y.astype(np.int32)).sum())\n",
        "        dot1 = int((Xg.astype(np.int32)*Yg.astype(np.int32)).sum())\n",
        "        ok_iso &= (dot0 == dot1)\n",
        "        ok_inv &= np.array_equal(to_mem_tranche(Xg, G), X)\n",
        "    return {\"isometry_ok\": bool(ok_iso), \"involution_ok\": bool(ok_inv),\n",
        "            \"ok\": bool(ok_iso and ok_inv)}\n",
        "\n",
        "def validate_lsh_collisions(lsh: SignLSH, D: int, B: int = 1000, seed: int = 13, tol: float = 0.005) -> Dict[str, Any]:\n",
        "    X = ((np.random.default_rng(seed).integers(0,2,size=(B,D),dtype=np.int8)<<1)-1)\n",
        "    codes = np.array([lsh.code(x) for x in X], dtype=np.int64)\n",
        "    uniq = np.unique(codes).size\n",
        "    coll = 1.0 - uniq / B\n",
        "    return {\"collisions\": float(coll), \"uniq\": int(uniq), \"ok\": bool(coll <= tol)}\n",
        "\n",
        "def monitor_lln_majority(mem: MemBank, classes: np.ndarray, step: int = 1) -> Dict[str, Any]:\n",
        "    \"\"\"Estime que le seuillage est stabilisé : H == sign(M) (sous thresh=True).\"\"\"\n",
        "    stable = True; mism = 0; tot = 0\n",
        "    for c in classes[::step]:\n",
        "        signM = np.where(mem.M[c] >= 0, 1, -1).astype(np.int8, copy=False)\n",
        "        diff  = (signM != mem.H[c])\n",
        "        mism += int(diff.sum()); tot += diff.size\n",
        "        stable &= not np.any(diff)\n",
        "    rate = mism / float(max(1, tot))\n",
        "    return {\"majority_mismatch_rate\": float(rate), \"ok\": bool(stable)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd97b48",
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimate_ram_bytes(mem: MemBank) -> int:\n",
        "    return int(mem.M.nbytes + mem.H.nbytes + mem.n.nbytes)\n",
        "\n",
        "def measure_train_latency(comp, pairs, warmup: int = 100) -> dict:\n",
        "    mem, lsh, G = comp.mem, comp.lsh, comp.Gmem\n",
        "    D = int(G.shape[0])\n",
        "    items = list(pairs)\n",
        "    w = min(warmup, len(items))\n",
        "    # Warmup\n",
        "    for i in range(w):\n",
        "        Z_en, Z_fr = items[i]\n",
        "        Z_en = Z_en.astype(np.int8, copy=False); Z_fr = Z_fr.astype(np.int8, copy=False)\n",
        "        Z_en_mem = to_mem_tranche(Z_en, G)\n",
        "        c = _lsh_bucket(lsh, Z_en_mem, mem.B)    # *** FIX ***\n",
        "        mem.add(c, Z_fr)\n",
        "    # Mesure\n",
        "    t0, n = time.perf_counter(), 0\n",
        "    for i in range(w, len(items)):\n",
        "        Z_en, Z_fr = items[i]\n",
        "        Z_en = Z_en.astype(np.int8, copy=False); Z_fr = Z_fr.astype(np.int8, copy=False)\n",
        "        Z_en_mem = to_mem_tranche(Z_en, G)\n",
        "        c = _lsh_bucket(lsh, Z_en_mem, mem.B)    # *** FIX ***\n",
        "        mem.add(c, Z_fr); n += 1\n",
        "    dt = time.perf_counter() - t0\n",
        "    return {\"count\": int(n), \"avg_ms_per_update\": float(1000.0*dt/max(1,n))}\n",
        "\n",
        "def measure_margins(comp: MemComponents, R_list) -> Dict[str, Any]:\n",
        "    margins = []\n",
        "    for R in R_list:\n",
        "        Rm = build_query_mem(R, comp.Gmem)\n",
        "        s  = mem_scores(comp.mem, Rm, use_thresh=True)\n",
        "        margins.append(margin_top1(s))\n",
        "    return {\"margin_mean\": float(np.mean(margins)), \"margin_min\": float(np.min(margins))}\n",
        "\n",
        "def log_metadata(comp: MemComponents) -> Dict[str, Any]:\n",
        "    md = dict(comp.meta)\n",
        "    md[\"ram_bytes\"] = estimate_ram_bytes(comp.mem)\n",
        "    return md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3925e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_mm10_checklist(cfg: MemConfig,\n",
        "                       synth_params: Tuple[int,int,float,float,int,int] = (32, 0.01, 0.01, 100, 101, 102),\n",
        "                       eps_leak: float = 0.05) -> Dict[str, Any]:\n",
        "    \"\"\"Lance tous les contrôles MM10 et renvoie un rapport structuré.\n",
        "\n",
        "    synth_params = (m_per_class, noise_fr, noise_en, seed_proto, seed_stream, seed_infer)\n",
        "    CA par défaut :\n",
        "      - étanchéité: |mean| ≤ 1e-2 & tail ≤ Hoeffding\n",
        "      - collisions: ≤ 0.5% (k≥24, B≈1e3)\n",
        "      - préc@1 (requêtes propres): ≥ 99.5%\n",
        "      - LLN/majorité: mismatch_rate ~ 0\n",
        "      - isométrie/involutivité: OK\n",
        "      - perf: latence ∝ D (indicative)\n",
        "    \"\"\"\n",
        "    m_per_class, noise_fr, noise_en, seed_proto, seed_stream, seed_infer = synth_params\n",
        "\n",
        "    # 1) Construction pipeline + données synthétiques alignées\n",
        "    comp = make_mem_pipeline(cfg)\n",
        "    data = make_aligned_pairs(cfg.B, cfg.D, m_per_class, noise_fr, noise_en, seed_proto, seed_stream)\n",
        "\n",
        "    # 2) Validateurs de base\n",
        "    v_types = validate_types_shapes(comp.mem)\n",
        "    v_tr    = validate_tranche_isometry(comp.Gmem, D=cfg.D)\n",
        "    v_lsh   = validate_lsh_collisions(comp.lsh, cfg.D, B=min(cfg.B,1000))\n",
        "\n",
        "    # 3) Entraînement one-pass\n",
        "    train_one_pass_MEM(comp, data[\"pairs\"])\n",
        "\n",
        "    # 4) LLN/majorité (vérif rapide)\n",
        "    classes = np.arange(cfg.B, dtype=np.int64)\n",
        "    v_lln = monitor_lln_majority(comp.mem, classes, step=max(1, cfg.B//16))\n",
        "\n",
        "    # 5) Étanchéité (inter-tranches)\n",
        "    leak = accept_leakage(D=cfg.D, n=4000, eps=eps_leak)\n",
        "\n",
        "    # 6) Précision@1 sur requêtes propres (e2e)\n",
        "    e2e = accept_train_infer_precision(cfg, m_per_class, noise_fr, noise_en, seed_proto, seed_stream, seed_infer)\n",
        "\n",
        "    # 7) Performance (latence moyenne / update)\n",
        "    perf = measure_train_latency(comp, data[\"pairs\"])\n",
        "\n",
        "    # 8) Marges (sur les requêtes propres)\n",
        "    marg = measure_margins(comp, data[\"R_clean\"])\n",
        "\n",
        "    # 9) Métadonnées / RAM\n",
        "    meta = log_metadata(comp)\n",
        "\n",
        "    # 10) Agrégation Go/No-Go\n",
        "    ok = (v_types[\"ok\"] and v_tr[\"ok\"] and v_lsh[\"ok\"] and v_lln[\"ok\"] and leak[\"ok\"] and e2e[\"ok\"])\n",
        "    report = {\n",
        "        \"ok\": bool(ok),\n",
        "        \"types\": v_types, \"tranche\": v_tr, \"lsh\": v_lsh, \"lln_majority\": v_lln,\n",
        "        \"leakage\": leak, \"e2e_prec1\": e2e, \"perf\": perf, \"margins\": marg, \"meta\": meta\n",
        "    }\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "543d2c16",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class MemConfig:\n",
        "    # --- hyperparamètres ---\n",
        "    D: int              # dimension HD\n",
        "    B: int              # capacité mémoire (nb de buckets/classes)\n",
        "    k: int              # nombre de bits LSH (MM3)\n",
        "    seed: int           # seed globale pour reproductibilité\n",
        "    seed_lsh: int       # seed spécifique pour LSH\n",
        "    seed_gmem: int      # seed spécifique pour tranche G_MEM\n",
        "    thresh: bool = True # seuillage en-ligne (MM4)\n",
        "\n",
        "    # --- objets instanciés ---\n",
        "    mem: \"MemBank\" = None\n",
        "    lsh: \"SignLSH\" = None\n",
        "    Gmem: np.ndarray = None\n",
        "\n",
        "def make_memconfig(D=4096, B=256, k=24, seed=42, thresh: bool = True) -> MemConfig:\n",
        "    \"\"\"Fabrique une configuration mémoire complète pour les tests MM10.\"\"\"\n",
        "    # dérive des seeds pour LSH et Gmem à partir du seed global\n",
        "    seed_lsh = seed + 1\n",
        "    seed_gmem = seed + 2\n",
        "\n",
        "    # clé de tranche ±1 int8 (seed_gmem)\n",
        "    rng = np.random.default_rng(seed_gmem)\n",
        "    Gmem = rng.choice([-1, +1], size=D).astype(np.int8)\n",
        "\n",
        "    # indexeur LSH (seed_lsh)\n",
        "    lsh = SignLSH.with_k_bits(D, k, seed=seed_lsh)\n",
        "\n",
        "    # banque mémoire\n",
        "    mem = MemBank(B=B, D=D)\n",
        "\n",
        "    return MemConfig(\n",
        "        D=D, B=B, k=k, seed=seed,\n",
        "        mem=mem, lsh=lsh, Gmem=Gmem,\n",
        "        seed_lsh=seed_lsh, seed_gmem=seed_gmem,\n",
        "        thresh=thresh,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "4e6f2ebe",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'validate_types_shapes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m cfg = make_memconfig(D=\u001b[32m4096\u001b[39m, B=\u001b[32m256\u001b[39m, k=\u001b[32m24\u001b[39m, seed=\u001b[32m123\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m report = \u001b[43mrun_mm10_checklist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mrun_mm10_checklist\u001b[39m\u001b[34m(cfg, synth_params, eps_leak)\u001b[39m\n\u001b[32m     19\u001b[39m data = make_aligned_pairs(cfg.B, cfg.D, m_per_class, noise_fr, noise_en, seed_proto, seed_stream)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 2) Validateurs de base\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m v_types = \u001b[43mvalidate_types_shapes\u001b[49m(comp.mem)\n\u001b[32m     23\u001b[39m v_tr    = validate_tranche_isometry(comp.Gmem, D=cfg.D)\n\u001b[32m     24\u001b[39m v_lsh   = validate_lsh_collisions(comp.lsh, cfg.D, B=\u001b[38;5;28mmin\u001b[39m(cfg.B,\u001b[32m1000\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'validate_types_shapes' is not defined"
          ]
        }
      ],
      "source": [
        "cfg = make_memconfig(D=4096, B=256, k=24, seed=123)\n",
        "report = run_mm10_checklist(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de4cad2c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "938faee8",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
